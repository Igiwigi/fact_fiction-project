The better strategy is to approach the problem incrementally. Some of the risks likely to be
posed by AI technology are already apparent, and legal or regulatory action can be taken now
to deal with them. Others will make themselves known as the technology becomes more widely
used and can be dealt with in the same way. At some point, it will become apparent whether
specific regulation is needed, and if so the scope and focus of that regulation will be possible to
devise. But at present, we are some distance away from that point.

This should not be taken as a call for complete inaction. Working to understand the risks posed
by AI developments and the possible legal and regulatory responses to them would be highly
desirable, and this could be undertaken by establishing a new, non-regulatory body for that
purpose [6] or by extending the remit and funding of existing agencies [7]. Properly informed
analysis on these matters will help to ensure that the current law and regulation is applied
most appropriately, identify when regulation is in fact needed, and decrease the likelihood of

unnecessary or ineffective regulation in the future. : =

To illustrate the argument that existing law and regulation is largely able to cope with the : S
immediate problems posed by AI, this article examines two potential risks (the infringement : 2
of fundamental rights, and the causing of loss or damage as the result of an AI decision) and 14
one possible legal change (requiring transparency about the AIâ€™s decision-making process). The _
main focus is on areas of activity where there is no existing regulatory regime which concerns a]
itself with the decision-making process of actors, and thus AI technology can be adopted without 7s
regulatory approval or oversight. In already regulated sectors, such as medical treatment and : 3
aviation, sector-specific regulatory change will of course be needed at the time of, and quite : &
