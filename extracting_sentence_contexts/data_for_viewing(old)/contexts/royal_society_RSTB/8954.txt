entire planning process). The downward slope of each data- grained events that make up those sequences are difficult to
series indicates the speed with which the relevant agent is simulate or predict. For example, one may be able to judge
able to converge on the optimal policy. quite accurately the probability of defeating a particular
The violet data-series in figure 2a shows the time-course of opponent in a game of chess, even without the ability to pre-
planning for a flat RL agent. The orange data-series shows the dict what moves that opponent will be prone to make in the
time-course for a MB-HRL agent. This latter agent carries pre- game itself (an ability that would clearly be out of reach if
cisely the same model as the flat agent but is also provided with the opponent happened to be a superior player).
a set of options, each specifying a policy for reaching one of the Another important advantage of saltatory MB-HRL
doorways in the rooms domain. As the figure makes clear, relates to the representation of environmental state. When
the ability to ‘try out’ these subgoal-oriented options, alongside planning using a primitive-level model, it is necessary to
primitive one-step actions, yields a dramatic reduction in keep track of the current (projected) situation at each step
planning time. of a candidate action sequence. Depending on the problem
This effect stems from the fact that options structure the domain, this can require tracking detailed features of the
agent’s search among candidate behaviours, guiding that environment that may not be important at the level of the
search into channels that fit well with the organization of overall plan. For example, a detailed simulation of the activity
the problem domain (see [20]). This pay-off is precisely analo- of preparing pasta would require maintaining an explicit
gous to the one gained by adding temporal abstraction to record of factors such as whether the sink tap is running,
model-free RL [10]. The only difference is that in MF-HRL whether the stove is on, whether there is water in the pot
the agent learns a policy through direct interaction with the and whether that water is boiling. In a saltatory context,
environment, whereas in MB-HRL, the search is conducted where one can simply jump to the conclusion of the activity
using an internal model of the environment. (a plate of cooked pasta), it may be safe to ignore these tran-
Planning by way of an internal model has the benefit that siently important features of the environment, either because
it can relieve the agent from having to ‘make mistakes’ in the execution of the activity will itself assure that they are
real world, allowing it to work out a good plan before having restored to acceptable defaults (e.g. sink and stove both
to interact directly with the (potentially dangerous) environ- off), or because they are truly irrelevant to subsequent activ-