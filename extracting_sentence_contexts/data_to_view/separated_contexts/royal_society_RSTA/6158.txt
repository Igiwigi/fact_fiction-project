In particular, they place greater weight on larger observed values!”

°The value 1 in equation (2.5) is arbitrary. While x(y |£) is strictly a probability density, the fact that it is unnormalized does
not matter because the posterior probability in equation (2.4) is only known up to a constant of proportionality.

1For example, taking the difference between Y; and y; and squaring would result in something akin to a least-squares
approach.

"Its value is set to 2% of the highest peak from the time series to which the measurement i belongs. This was a simple way to
suppress the effect of noise in measurements with low values.

2-This reflects the fact that daily transitions, like case and death data, are expected to be Poisson distributed, and so larger
values are expected to be less susceptible to stochastic variation than smaller values.


and overall give an approximately equal weighting to each of the time series in the data! (see 8 |
electronic supplementary material, appendix I for details).

(ii) The latent process likelihood L(é|@) ig

This gives the probability of simulating a state € given a set of model parameters 6 (see electronic : Reg
supplementary material, appendix E, for an expression for this quantity). It should be noted, :
however, that the MBPs used below are ‘likelihood-free’, so L(é | 9) is not explicitly calculated.

(iii) The prior zz (0)

This captures the state of knowledge regarding parameter values before data y is considered. Prior specifications are given for all model parameters in Table R1 of the electronic supplementary :3
results (see electronic supplementary material, appendix J, for further explanation).