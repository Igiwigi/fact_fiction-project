of expressions produced by males. Full details of the groups clips collected, this yielded a total of 506 codable videos. In 142 of
and the individuals followed are shown in table 1. In focal obser- these, the signaller or receiver was unknown, meaning dyadic
vations, two observers followed an individual at a distance of 3- information was not available. The remaining 364 clips, showing
20 m, depending on terrain, vegetation, and the location of the facial movements of 35 different individuals in total, were FACS
individual within the group. One observer kept a video camera coded and analysed. Each clip showed a single interaction, in
(Panasonic HDC-SD700, Bracknell, UK) trained on the animal’s which both signaller and receiver were individually recognizable
face and activated the pre-record function on the camera when- adults or subadults, enabling the calculation of standard measures
ever a facial movement was produced and whenever another of dominance relationship and social bonds (detailed below).

individual approached or was approached by the focal animal.
The other observer used a tablet computer with a purpose-

built macro in Microsoft Excel to collect continuous behavioural (d FACS coding

data, including general activity (move, rest, forage etc.) and Video clips were coded using BORIS [39] by a certified MaqFACS
detailed records of social interactions, and scan data (every five coder (P.C.) following the guidelines of MaqFACS [29], which are
minutes) including identity of any other individuals within 1 m applicable to crested macaques with minor alterations [17]. To
and 5 m. Since both camera and tablet recorded timestamps of minimize the coder’s knowledge of the context of each video
recordings, it was possible to match video clips with social inter- clip, the clips were trimmed to cover only the period during
actions recorded in the focal files. In addition to the video which facial movements were observed. We coded whether the
footage obtained from focal animals, we captured some video focal animal was looking at the target individual—based on the
footage of facial movements produced by non-focal animals, direction of the face during the majority of facial movements—
either when the non-focal animal interacted with the focal and analysed only the movements produced when either (a) the
animal being followed, or opportunistically in between focals. animal was looking at the target individual or (b) the animal
