The consequence of de Finetti’s theorem is that if we want to model exchangeable data in full
generality, we need to consider putting distributions on unknown probability measures. Distributions on measures, functions and other infinite-dimensional objects are thus central
to Bayesian non-parametric modelling. Many of these distributions are infinite-dimensional
versions of their finite-dimensional counterparts, and in fact a good strategy for deriving Bayesian
non-parametric models is to start from a parametric model and ‘take the infinite limit’ [20]. Distributions on infinite-dimensional objects are the main subject of study in stochastic process
theory, and therefore much of the terminology used in Bayesian non-parametrics is borrowed
from this field.”

Two of the classical building blocks for Bayesian non-parametric models are the Gaussian
process (GP) and the Dirichlet process (DP). I will give an overview of these models in §§4 and
5, with an emphasis on their applications to general problems in machine learning and statistics,
including regression, classification, clustering and density estimation (these problems will also
be described in those sections).