which allows the neuron to respond in a graded and reprodu- responses from different subsets of neurons within the popu-
cible way to input stimuli of varying intensity (figure 6). lation to avoid all stimuli looking ‘the same’ to the neural
Fourth, in general the reference weight w is not fixed, but fol- circuit. Finally, individual neurons should respond sparsely
lows its own temporal dynamics on a slower timescale over time. Imagine a neuron which is active for all possible
(~20 min and more). Such slow complex synaptic dynamics stimuli. It would be as uninformative as one which never
are essential to capture experiments on synaptic consolida- responds to any of the inputs. Therefore, to represent and
tion [50,54,121], but could similarly be used to model slow process information in neural populations efficiently, differ-
forms of homeostatic plasticity [17]. ent neurons in the population have to develop selectivity to
Finally, the stability properties of the learning rule in different features.
equation (7.1) are not limited to simple feed-forward circuits, Multistable plasticity at the neuronal level as described
but generalize to more realistic scenarios. Specifically, the above does not prevent neurons from responding weakly to
combination of heterosynaptic and Hebbian plasticity enables all stimuli (see, for example, Neuron 2 in figure 5f). This is
stable online learning and recall of cell assemblies in large a direct consequence of the fact that the model presented
spiking neural networks (figure 7a,b; [103]). Stationary here does not have a sliding threshold like the BCM model.
firing rates in the model depend on the connectivity pattern Moreover, with more similar initial conditions and in the
and the spiking statistics of active inputs. In a recurrent net- absence of lateral inhibition both Neurons 1 and 2 could
work, however, output spike trains pose as inputs to other have developed selectivity to the same input. Thus, in a
neurons. As a non-trivial consequence, stationary solutions large network in which all synapses are changed by the
of the network state exhibit firing rate distributions which intrinsically stable plasticity rule introduced above, all neur-
are unimodal and long-tailed (figure 7c,d). Individual neur- ons could end up responding to the same feature. How can
onal firing rates only stabilize under stationary conditions. such an undesired outcome be avoided?
If the rates are non-stationary, for instance, owing to the To successfully implement network functions like the
inclusion of additional adaptation processes in the neuron ones shown in our example (figure 7), several network par-
model, rates in the model drift on behavioural timescales ameters and properties of the learning rules themselves
(see Zenke et al. [103] for details). need to be fine-tuned and maintained in sensible parameter