
1872

Figure 1. From Darwin to deep-learning: rapid technological advances in artificial intelligence create opportunities for real-time algorithmic modulations of facial
and vocal expressions, which raises unprecedented societal and ethical questions. From left to right: (a) original studies of human facial expressions employed electric
stimulation to induce muscle contraction (Guillaume Duchenne de Boulogne, reproduced in [1]); (6) manipulation of individual action units in still photographs using
Generative Adversarial Networks (GANimation [14]); (c) real-time smile filters in commercial video sharing plateforms (Tiktok, ByteDance Ltd., Beijing, China); (d) still
from the ‘Arkangel’ episode of dystopian science fiction television series Black Mirror (Endemol Shine UK Ltd., 2017) in which parents equip their children with anti-
violence visual filters via a brain implant. Here, the device visually filters out a dog aggressively barking at the child, directly in the child’s mind. (Online version in
colour.)

difficult to trust whether the smiles, laughs and frowns of create opportunities for highly desirable situations. First, the
our conversation partners are genuine or algorithmically fact that, e.g. a smiling voice transformation can be used to
modulated (figure 1c). appear happier than one really is becomes highly desirable
The goal of this paper is to initiate the data-driven study in the case of patients who cannot easily express emotions
of expressive deep-fakes ethics (specifically here, vocal deep- (e.g. amyotrophic lateral sclerosis patients who rely on assis-
fakes) and, inspired by the methodology of ‘experimental tive voice technology for communication, [22]). Second, the
ethics’ [16], to quantify societal expectations about the fact that voice or face transformations can coerce observers
principles that should guide their deployment. into subsequent actions can be desirable in interventions
The realistic, artificial manipulation of expressive behav- where people are nudged into positive behaviour [23], for
iour raises unprecedented societal and ethical questions. instance reducing aggressive behaviour in call-centre conver-
First, it raises concerns about truthfulness. Because expressive sations by transforming the operator's fatigued voice [24], or
behaviours are often thought to provide genuine cues about applying a gender voice transformation on an online hiring
the sender’s emotional states [17], the ability to arbitrarily platform to alleviate gender biases [21] (figure 2, top). Third,
manipulate these displays opens avenues for deception: one the fact that expressive transformations can be processed