First, arbitrating between creating new changes based on the inconsistency between actual action out-
strategies versus adjusting previously learned ones is in essence comes and the outcome contingencies the actor has learned so
non-parametric. This requires optimal adaptive processes to far. Such inferences are factual as they only bear upon the out-
systematically re-evaluate offline past arbitrations whenever come predictive model the actor strategy has learned, and
new information is acquired and consequently, to revise the reactive as they operate only after observing action outcomes.
repertoire of previously learned strategies in a backward To make such inferences, the actor thus learns both a
fashion. Second, optimal adaptive processes require monitoring selective and predictive model: the former maps stimuli onto
online the whole repertoire of learned strategies that con- actions, adjusts through RL and enables selection of the most
tinuously increase when new strategies are created. These rewarding actions in response to stimuli; the latter maps stimu-
computational requirements for optimal arbitrations rapidly lusâ€”action associations onto expected outcomes and. learns
yield to intractable computations, suggesting that the prefron- by simply registering outcome frequencies given responses
tal cortex has evolved as implementing online only forward to stimuli.