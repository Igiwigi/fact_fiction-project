these paradigms, the information pertaining to the decision-
relevant variables is processed by verbal and mental calcu-
lation systems and relies upon some degree of semantic
knowledge to decode the meaning of the symbols used. In
addition to that, decision problems were usually presented
only once and, in case multiple decision problems were
used, the final outcome (i.e. the realization of the lottery)
was usually not displayed on a trial-by-trial basis (figure 2b).

However, relatively few situations in real life match the
characteristics of the pure description-based paradigms, namely
complete and explicit information about outcome values and
probabilities. In fact, in many circumstances, it seems rather
prudent to assume that information about outcome values
and probabilities are shaped by past encounters of the same
decision problem. Experimentally, this configuration is often
translated into multi-armed bandit problems (starting with
Thompson [59], but see [60] for a review), where the decision-
maker faces abstract cues of unknown value and has to figure
by trial-and-error the value of the options. Computationally,
behaviour in multi-armed bandit problems is generally well-
captured by associative or reinforcement learning processes


(a) description experience