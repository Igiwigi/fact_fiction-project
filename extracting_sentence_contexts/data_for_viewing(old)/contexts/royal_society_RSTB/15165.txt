To date, processes such as causal inference or predictive facilitate the subsequent perception of objects in any modality
coding have mainly been proposed to explain cross-sensory [80]. Indeed, this facilitation is likely to occur during a later,
interactions for perception and have not adequately been con- post-sensory, stage in information processing. For example,
sidered in models of the formation of multisensory object using EEG, Franzen et al. [81] reported evidence that the
categories in memory, despite the relevance. Given the visual perception of familiar objects, such as faces or cars, is
increasing knowledge of multisensory interactions in the facilitated by semantically congruent sounds (speech or
brain, we argue that there is a timely need for an extension engine noises, respectively) at a late stage associated with
of these models. For example, traditionally it was assumed decision-related processing.
that multisensory integration occurred late in information Taken together, the results of investigations into the multi-
processing, underpinned by activations in association cortex sensory perception of objects suggest that the reliability of
or beyond in neural structures supporting associative learn- sensory information and learned associations across modalities
ing and memory. However, evidence for crossmodal can directly influence perceptual decisions [82]. These processes
interactions in primary sensory regions of the brain, revealing are, in fact, not likely to be mutually exclusive since sensory
plasticity changes to multisensory inputs at all stages of brain information about familiar objects can vary in its reliability
processing, is now overwhelming [53]. Indeed, the past few (e.g. incidentally or with developmental changes), and the pre-
decades have witnessed growing evidence for multisensory dictive nature of an objectâ€™s features may differ across

interactions within primary sensory regions of the brain, modalities. Indeed, research into multisensory object perception


suggests that categories may be shaped by all relevant infor-
mation available, often in a flexible way according to task
demands. To date, however, investigations into the formation
of object categories across multiple features [83] or dimensions
[84] have mainly been based on visual processing [85], although