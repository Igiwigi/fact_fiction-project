ler’ representations (with fewer active neurons). In addition, this some features, which in fact characterize only some category =~
makes it easy to increase the distance between representations instances, were shared by all category members. =
(by adding new active neurons) and thus increase dissimilarity 3
but more difficult to decrease dissimilarity, especially if, as in
the present simulations, representational patterns are chosen (b) Limitations and future research needs
that strongly overlap in the first place. It may be that when In spite of the present attempts to look more closely at the
using a different dissimilarity measure (e.g. cosine dissimilarity mechanisms by which verbal labels may aid semantic cat-
or a measure normalized for ‘representational size’ or vector egory learning, this work leaves many related questions
length) the results will change in such a way that within- and unanswered. We believe that a likely mechanism is owing
between-category dynamics appear more comparable in size. to the differing patterns of correlations that (i) the semantic-
We suggest not over-emphasizing this difference between feature neurons, on the one hand, and (ii) the word form
within- and between-category dissimilarities, but instead con- neurons and semantic-feature neurons, on the other, exhibit
sider both facts, each of which is based on significant results, for concrete and abstract concepts. A proposed explanation
as relevant. is that the relatively stronger correlation between label and

As the label-induced ‘moving apart’ of different categories semantic neurons (see the Introduction and figure 1 for expla-
in representational space seems to have received less attention nation) for abstract concepts exerts a ‘pull’ on the emerging
in previous work compared with the ‘moving together’ of rep- cell assemblies during training such that the word form neur-
resentations within the same category, we now turn to the ons play a larger role in the entire semantic cell assembly than
mechanisms underlying the increase of dissimilarity between they do for concrete concepts. However, to assess this sugges-
categories related to language. The addition of different tion in detail, one would need to follow the formation of
labels to conceptual representations in a network can be mod- novel cell assemblies for concepts and then semantic concep-
elled in an elementary way by adding a different activation tual-linguistic representations step by step throughout the
vector — representing the added word form — to each concept learning process. Most importantly, we assume and suggest
vector. For instances (i.e. objects, actions or scenes) from the that the implemented associative learning between concrete