Text-only
language models are not. However, the face-validity of the premise hides the subtlety of what
is at-issue in the conclusion. In fact, there is not consensus among philosophers and cognitive
scientists about the extent to which grounding is a key component of what we conventionally
refer to when we use the word ‘meaning’. Here, it is worth differentiating claims about the need for communicative intent from claims [2
about the need for an external world more generally. (Perception is the most obvious example : >
of the latter category, but there are other examples, e.g. an agent’s non-communicative goals.) :8
Arguments against LLMs often entangle both into a generic notion of grounding, but these claims : -
are not the same. They inherit from separate philosophical traditions and thus have separate sets : <
of criticisms to address. (cf. [71,72] who present partially overlapping arguments with the ones I _
make below.) : 8

SI
(i) Does meaning require communicative intent? 8

A common line of argument is that LLMs cannot encode meaning because they lack
communicative intent.