dependencies are largely ignored.

Beyond the practical problem of needing to marginalize
over all the senses and states, there is also a conceptual
problem in that Bayesian multisensory models purport that multisensory processing a host of brain functions that deal
some brain circuit receives ‘unisensory’ observations as
input. For example, the well-known ‘causal inference’ model
[2] (figure 1b) describes how best to decide whether two
unisensory observations (e.g. audio, xq and visual, xy) were different purposes, including
caused by one source (C = 1, bottom left panel), in which case integration, suppression, etc.
they should be integrated, or two separate sources (C =2,
bottom right panel), in which case they should not be inte-
grated. But these ‘unisensory’ observations are in fact each a
result of multisensory processing. They depend on the states modalities into a unified estimate
and input from other senses (grey circles and arrows in of the stimulus
figure 1b), e.g. proprioceptive signals from the eyes and neck,
vestibular signals from the head, and corollary discharge
from intended movements, all strongly influence visual and
auditory observations [5,6,37-41]. presence of another stimulus from

a different modality

with multiple sensory modalities’
inputs and states—for a variety of
