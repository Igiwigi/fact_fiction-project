our conversation partners are genuine or algorithmically fact that, e.g. a smiling voice transformation can be used to
modulated (figure 1c). appear happier than one really is becomes highly desirable
The goal of this paper is to initiate the data-driven study in the case of patients who cannot easily express emotions
of expressive deep-fakes ethics (specifically here, vocal deep- (e.g. amyotrophic lateral sclerosis patients who rely on assis-
fakes) and, inspired by the methodology of ‘experimental tive voice technology for communication, [22]). Second, the
ethics’ [16], to quantify societal expectations about the fact that voice or face transformations can coerce observers
principles that should guide their deployment. into subsequent actions can be desirable in interventions
The realistic, artificial manipulation of expressive behav- where people are nudged into positive behaviour [23], for
iour raises unprecedented societal and ethical questions. instance reducing aggressive behaviour in call-centre conver-
First, it raises concerns about truthfulness. Because expressive sations by transforming the operator's fatigued voice [24], or
behaviours are often thought to provide genuine cues about applying a gender voice transformation on an online hiring
the sender’s emotional states [17], the ability to arbitrarily platform to alleviate gender biases [21] (figure 2, top). Third,
manipulate these displays opens avenues for deception: one the fact that expressive transformations can be processed
may use, e.g. a facial filter to fake a smile despite having no unconsciously may be desirable in situations where this
intent to affiliate, or a voice transformation to appear more increases their effectiveness, as seen in emotional vocal
certain than one really is. Second, they raise concerns about feedback [25].
fairness. Expressive behaviours in verbal interactions strongly Societal expectations in such situations are non-trivial and
influence subsequent behaviours. It is already known that important to understand in order to inform and regulate the
vendors displaying positive, authentic expressions while deployment of deep-fakes in commercial products or clinical
interacting with customers sell more mobile phones [18], or protocols. A recently emerging methodology for doing so is
that negotiators faking anger in commercial discussions that of experimental ethics, in which moral judgements about
obtain better prices [19]. The algorithmic manipulation of various situational vignettes are collected from relatively large
expressions designed for such situations may coerce people samples of online participants. In recent years, this method-
into making unwarranted or unfair decisions. Third, they ology has been applied to quantify societal attitudes towards
raise concerns about autonomy. Non-verbal influences on new technologies such as autonomous vehicles [16] or brain