The video, prosaically named The Knowledge Navigator (https://www.youtube.com/ :2
watch?v=umJsITGzXd0), introduces many innovations and improvements on already existing :s
functionalities that people take for granted today, including text-to-speech, multi-touch and :8
gesture interfaces, fluid videoconferencing, powerful search engine, self-updating databases, all 7g
of it on a tablet that prefigures by a long stretch what most people use today without thinking
about where it came from or how. But the most striking and least foreseeable function was the
navigator itself, a friendly bow-tied normal human-faced avatar answering questions from the
user, reminding him of appointments, sending messages to the right person at appropriate times,
and making suggestions. In other words, doing just what Alexa or Siri do today, except that
neither presents a human face, only human voices and, during a variety of exchanges with their
human user, exhibiting typically human tonal responses factual, humorous or critical depending
on the context. Although digital assistantship has become a home appliance for a growing number of
households, it is not yet a ‘twin’. Even if the assistant’s machine learning ability gathers ever
more information about the user, that information is still too specialized and fragmentary to
genuinely duplicate the user, in spite of having access to vast amounts of data and powerful
data analytics.