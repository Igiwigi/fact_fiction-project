In this context, the work of Ribeiro, Singh and Guestrin [42] is of interest. Their experiment—
in respect of classifiers that were trying to determine if a document was about Christianity or
atheism—used a dataset that, despite a high accuracy on validation data, contained features
that did not generalize, and thus validation accuracy overestimated real-world performance [42]. When test set accuracy was used as a measure of trust in order to choose between two text
classification models, users tended to select the worse classifier, i.e. the classifier that, despite
achieving a high percentage accuracy rate, in fact had serious issues ‘in the wild’ due to the
importance given to irrelevant words (such as ‘Posting’ and ‘Re’). When individual prediction
explanations were shown, however, it was possible for a human user with prior knowledge to see

‘Short v. Poole Cpn. [1926] Ch. 66.


if a prediction was made for arbitrary reasons unconnected with the purpose of the prediction,
and so take steps to improve an untrustworthy classifier [42].

(c) Risk assessments and predictions

Riberio et al.'s experiment was in respect of a definitional classification.