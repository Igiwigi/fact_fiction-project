
A common approach is to frame the output of the oo)
perceptual system as a continuous estimate of the relevant (b) Top-down influences on multisensory processing S
environmental variable, leading to frameworks such as maxi- Psychology has long grappled with the nature and extent s
mum-likelihood estimation. Ultimately, however, a percept of ‘top-down’ influences on perception [9-11], and neuroanat- S
must guide discrete behavioural choices, invoking the con- omy alone tells us that sensory pathways receive extensive 2
cept of a decision as the application of a rule or policy to feedback and recurrence even at early stages [12-14]. A new
the sensory evidence. Moreover, the evidence usually arrives surge of interest in this topic centres on exactly how the
not as a single snapshot but a temporal sequence or stream of synthesis of multisensory information is governed by these
information, and therefore we must decide not only what but higher order signals.
also when to commit to a decision. This perspective has a Pennartz et al. [15] zero in on the visual cortex in rodent
track record of success in the study of perceptual decisions models, marshalling an extensive body of evidence in support
based on individual modalities [1,2], but only recently has of the idea that this region is not, in fact, purely visual. Rather, it
it penetrated the multisensory field. incorporates signals from motivational, reward and motor sys-

Zeng et al. [3] review basic elements of ‘multisensory tems, in addition to other sensory modalities. They conclude
decision making’ as a novel application of perceptual decision that visual perception emerges from interactions between
frameworks (e.g. signal detection theory and evidence these systems, encompassing a large network of brain regions,
accumulation/ drift-diffusion) in a multisensory context. They and that these interactions can be understood within the
describe a set of classic studies on visual-vestibular integration framework of predictive processing.
for self-motion (heading) perception, and more recent attempts Stange et al. [16] investigate the influence of crossmodal
to understand how signals are integrated both across modal- predictions on neural processing in visual cortices by training
ities and over time—a computation made more difficult by participants to associate different sounds with spatially specific
the diverse dynamics of the constituent signals. At the core of visual signals. Using EEG, they show that when presented
this line of work is an intriguing mystery: several mid-level alone these sounds elicit spatially specific responses only at