grant no. R01 DC00491 from NIDCD, grant nos. R01 HD47450 and
Widening the lens on language to include the manual modality P01 HD40605 from NICHD and grant no. SBE 0541957 from NSF
has given us a deeper understanding of language learning to the Spatial Intelligence and Learning Center (the author is a co-PI).

and learning in general. Hearing children who are acquiring
spoken language use gesture along with speech to communi-
cate, and those gesture + word combinations precede, and

predict, the acquisition of word + word combinations convey- Endnotes

ing the same notions. These findings make it clear that children 'Estigarribia & Clark [18] have found that pointing gestures attract
have an understanding of these notions before they are able to and maintain attention in talk differently from iconic (or, in their
express them in speech, thus eliminating one frequently held terms, demonstrating) gestures, which may account for the fact that
explanation for the slow acquisition of certain structures—the pointing gestures predict the onset of nouns, but iconic gestures do

not predict the onset of verbs.
?This selectivity can be seen in the fact that the onset of complemen-
tary point + noun combinations (point at box + ‘box’) predicted the

cognitive explanation, that is, that children do not express a
given structure because they lack an understanding of the

notion underlying the structure. Widening our lens to include onset of determiner + noun combinations (‘the box’) in these 18 chil-
the manual modality thus allows insight into when cognition dren, but not the onset of two-word combinations containing a verb
does, and does not, shape the course of language learning. (e.g. ‘open box’), which is predicted by the onset of supplementary