Even software systems that are not based around learning from data can be

difficult or impossible to examine due to fundamental mathematical limitations within computer : =
science [15,16]. But even here, systems can be designed to sidestep these limits and to support that : a
interrogation—inscrutability remains a choice that can be accommodated for in system design. 73
Rather than discounting systems which cause bad outcomes as fundamentally inscrutable and aes
therefore uncontrollable, we should simply label the application of inadequate technology what 22
it is: malpractice, committed by a system’s controller. [4

Another common approach to dealing with inscrutability is to eschew attempts to understand : *
the system at all and to treat outcomes from computer systems as though they were unforeseeable : S
externalities analogous to pollution [17,18] or other sources of nuisance [19]. This analogy leads : &

scholars to look for remedies such as efforts-based liability regimes and to describe the impact
of biases in decisions made by machines as unavoidable, structural, environmental fact. But
arguing that the effects of a system are unforeseeable pre-apologizes for that system's failures. While demanding perfect foresight puts too much faith in engineering, it is certainly true
that systems which are designed to achieve certain goals in a trustworthy and verifiable way
can reasonably be judged on an absolute scale.