In particu-
interesting because it can perform pattern completion, lar, the first and third dimensions of the original dataset have
a general form of memory in which any fragment or approxi- been slightly altered, and a new dimension has been added
mation of an input pattern can be thought of as serving as a (direct comparisons of differences between the SVD’s can
potential cue for the reconstruction of all aspects of the pattern. be found in figure 8, where they are linked to dynamics we
Our linear auto-associator is also interesting in that it can be will explore below). The first dimension now reflects the
considered to capture one step of a recurrent computation in altered overall feature probabilities for the animals and the
which the output of the auto-associator is repeatedly fed third dimension reflects adjustments to these probabilities
back into itself, allowing the learned states in the network to needed to capture the average properties of the full set of
function as attractors. birds and fish. Dimensions 1 and 3 are now a bit stronger
When we train such a network with our dataset, the time than before, due to the added item participating in them, a

course of the development of the IO matrix (as before, the fact most easily seen in figure 8. The new dimension reflects


| singular values total summed error

6 10
dim. 1 before 8
= ‘
i 4]
dim. 1 after
== 2
0 0
0 1 2 3 4\5 0 12 3 4 ~°5
dim. 3 before >
s
mn]
|| new dimension after =
dim. 3 after ' =
a
~

Figure 8. Detailed analysis of the changes in the SVD of the network's output from the addition of the sparrowhawk to the eight-item training set, when trained  &
with full interleaved learning.