This is illustrated within our coded demonstration (doi:10. dependency representations will manifest as an increase in
5281 /zenodo.3464607). The inclusion of cross-serial depen- local activity as increasing numbers of neurons support the
dencies alters the minimum computational requirements for representation; as an example of this effect, consider the
any parsing agent [110], and thus it is important that a increased activity represented at the top of figure 3, relative
domain-general representational model has the potential to to the bottom. A ‘reset’ (or re-sparsification) of the buffer will
account for them as well as other language-like hierarchical result in a sudden drop in population activity. Such neural
constructions. accumulation and reset activity has been identified within

Having recoded a linear sequence in terms of its dependen- human intracranial recordings in subjects listening to sentences
cies, it is possible to recover one or more specific items from the containing words that accumulate into phrases [28]. Further-
representation of hierarchical structure by unbinding using more, representations of constituents might not persist
keys that specify context-specific position(s). With reference beyond the need to encode the reduced dependency represen-
to figure 3 and using this method: the key 712 will recover tation, a fact that highlights an interesting property of the
all position-item bindings of the first chunk; the key 727 model: detectable neural delay activity does not need to persist
will recover the second item of every chunk (with each still throughout working memory maintenance of the input
bound to information on the requisite chunk position); sequence, consistent with recently reported findings on the
and the key 7(2? ® 12) will recover the second item of neurobiology of working memory [115].
the first chunk. This flexible decoding scheme is important It must be emphasized that the flow diagrams in figure 3
because it readily supports manipulation of entire chunks only show symbolic information flow. There are likely to be
and generalization of dependencies to multiple timescales. sub-symbolic influences acting over time to hone the associated

A natural consequence of the above encoding scheme is neural activation patterns, requiring feedback and feedforward
that the superposition of many dependency representations interactions between neural ensembles in the model. These are
over time can gradually give rise to a memory trace. This briefly alluded to in figure 3 as a single exemplar (curved,
trace will be influenced by the probabilistic distribution of dashed arrow, left) denoting top-down influences acting on