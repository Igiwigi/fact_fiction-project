The ELBO interpretation is more fruitful as it shows the exact
objective one optimizes when using stochastic gradient ascent. Additionally, it also allows us

1q(u) can depend on 6,¢ and x but this is notationally omitted.


to optimize the algorithmic parameter ¢. However, standard gradient estimates of this ELBO
for ¢ have poor properties as K increases due to the fact that Liw(0,¢) becomes then almost
independent of ¢ (because of the convergence of the ELBO to the true log marginal likelihood),
and thus decreasingly strongly the signal-to-noise ratio of the estimator of Vg Liw(@,¢) [21]. One
can remedy this behaviour by using a ‘sticking the landing’ variance reduction approach [22] or
by doubly reparameterizing the gradient estimates of V¢Liw(0, @) [23]. In this section, we have presented a generic way to obtain an ELBO from any unbiased
positive estimate of the evidence.