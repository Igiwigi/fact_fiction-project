alone. Regular languages and Markov models are therefore rewrite rules expressing cross-serial dependencies in reference
not equivalent, and showing the inadequacy of n-grams or [114]). In contrast, such phenomena are frequent forms of form-

SLTLs is hence not sufficient by itself to prove the need to building in music [25] and animal song. This mismatch

move beyond finite-state or to the context-free level. between the simplicity of repetitive structures and the high
In reverse, the hierarchical nature of the extended CH CH class it is mapped onto might be one of many motivations

(and methodological problems in dealing with real-world to move beyond its confines.

data that we outline below) creates potential issues for
some arguments that the formalism producing a set of
sequences is constituted by a lower class: the mere fact that

a lower complexity model of structure could be built does 6. Moving towards different types of models

not constitute a valid form of argument or proves that the The CH has been extensively used in recent cognitive debates on
system in question is best modelled by this type of complex- human and animal cognitive capacities, discussing the complex-
ity. Particularly, the fact that Markov models may be easily ity of theories and processes in various domains and in
computed and used to describe some statistical features of characterizing different types of structures that may be learnable
corpora of music [26,105-107] does crucially not imply or in artificial grammar learning and implicit learning literatures
even underpin an argument that a Markov model is the [115]. However, discussions in many of these approaches relat-
best model (in terms of strong generative power, compression ing to the CH resulted in complex confusions concerning the
or model comparison, see §§6,7). A Markov model may be distinctions between the (formal) class of a language, the
computed from sequences generated from any deep structure formal automata producing/accepting formal languages and