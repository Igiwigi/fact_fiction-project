that speech perception is multimodal; what we perceive recognition of speech sounds based on partial infor-
as speech is influenced by what we see on the face of the mation. Darwin examines the effectiveness of the cues,
talker as well as by what is received at the two ears. This which can be used to separate target speech from a
is illustrated by the McGurk effect (McGurk & background of other sounds (including competing
MacDonald 1976), which is produced when a video speech), focusing particularly on the role of fundamental
recording of one utterance is combined with an audio frequency, onset asynchronies and binaural cues. At
recording of another utterance. What is heard is present, human listeners perform far better than any
influenced by what is seen. For example, an acoustic computer system in separating mixtures of sounds.

‘mama’ paired with a video ‘tata’ is heard as ‘nana’. A fuller understanding of how humans do this would
The influence of vision on speech perception is also have important practical applications.

illustrated by the fact that, in noisy situations, speech The paper by Patterson & Johnsrude (2008) places
can be understood much better when the face of the the study of auditory processing, as applied to speech,
talker is visible than when it is invisible (Erber 1974). squarely in a neuro-biological and neuro-imaging

Campbell proposes that there are two main ways or context. Cross-species studies—especially in the maca-
‘modes’ in which visual information may influence que—provide a well-developed neuroanatomical and
speech perception. The first is a complementary mode, neurophysiological account of the primate auditory
whereby vision provides information more efficiently processing system. This leads to concrete hypotheses
than hearing for some under-specified parts of the both about the detailed functional architecture of the
speech stream. For example, the acoustic cues human system, with subcortical auditory processing
signalling the distinction between ‘ba’ and ‘ga’ may systems feeding into primary auditory cortex, and about
be relatively weak and easily masked by background the local and the global connectivity of these areas with
sounds, whereas, visually, these two sounds are very other regions of the brain. In this general framework,