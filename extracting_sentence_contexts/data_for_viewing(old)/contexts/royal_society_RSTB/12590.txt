
properties. The root in dogs, for example, is dog, which may
3. Composite model of morphological processing have a feature for brown, fluffy, cute, small, mammal and
barks. The root itself is assumed to not be associated with
any particular word class—this is only determined once it
is combined with derivational morphology, as explained
below. So, in its acategorical form, I hypothesize that the
weights for each feature correspond to the average weight
given all the contexts of use of the word.

In NLP the meaning of words are routinely represented as
word embeddings (e.g. [5-8]). These are vectors created from the
statistical co-occurrence of words, capitalizing on the fact that
words that mean something similar often occur in similar con-
texts.> They provide a powerful way of representing meaning
and obey simple geometric transformations (for example, sub-
tracting man from kifig and adding womiin results in a vector
that closely approximates quéen [74]). These vectors are typi-

The discussion so far has reviewed the literature regarding
three stages of morphological processing. While neuro-
biological research provides quite a comprehensive explanation
of how the brain segments sensory input into morphological
constituents, our understanding remains poorly defined in
terms of (i) what linguistic features make up the representation