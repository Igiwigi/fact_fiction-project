a wide collection of privacy attacks, even those that are not currently known. More specifically,
formal models focus on provable limitations to excess harm due to participation in a computation,
regardless of the failure mode that occurred.

(iii) Expectations versus the scientific understanding

Regulatory standards that rely on the concept of de-identification to protect privacy are often
not in agreement with the current scientific understanding of privacy. For example, the HIPAA
Privacy Rule allows the publication of personal health records, as long as certain pieces of
information deemed to be identifying have been removed (see footnote 11). This is now
understood to be a weak standard, as research has demonstrated that redaction of identifiers
can fail to protect privacy, especially when applied to information that is very detailed, such as
that found in medical records. In fact, any information about individuals, including information
not traditionally considered to be identifying, has the potential to leak information specific to


individuals [23]. Moreover, this issue is not limited to HIPAA, as many legal standards of privacy
rely on the concepts of de-identification and personally identifiable information.

In some cases, the law may be interpreted to require something that is not technically feasible,
such as absolute privacy protection when sharing personal data. For example, Title 13 of the
US Code protects the confidentiality of respondent information collected by the US Census
Bureau by prohibiting ‘any publication whereby the data furnished by...[an] individual. ..can
be identified’ (see footnote 3). Whether an individual can be identified in a publication is not
precisely defined. If this concept were interpreted very conservatively, Title 13 would disallow