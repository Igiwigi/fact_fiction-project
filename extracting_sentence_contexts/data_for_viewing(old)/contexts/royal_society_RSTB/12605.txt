mation about what can be predicted to hold given the actual
circumstances. This focus on counterfactual information is in
common with several accounts of causal explanation (notably,
[4]). On its own, this focus on dependence does not yet provide
us with a solution to the problem of directionality. In Jansson
[8], | argued that we can provide a solution to the problem of
directionality when it comes to law-based explanations by
focusing on the lawâ€™s conditions of application. This solution
does not, however, cover the types of non-causal explanations
that we seem to find in network explanations where topologi-
cal properties are doing the explanatory work. To start to cover
such network explanations, I need to say a little more about the
schematic structure of explanatory models of physical facts that
Iam working with. I take the process of giving a model expla-
nation to have as a target a dependence external to the model
(type 4) and to have three steps that are of interest when captur-
ing the directionality of network explanations (dependence of
types 1-3) (figure ps

First, we can ask how features of the model selected vary
with features of the explanatory target (type 1). Here, the
model's conditions of application are crucial. When we are
selecting a model for some particular explanatory target, we
typically confront questions about whether or not a particular
model is apt. For example, in order to judge whether a particu-