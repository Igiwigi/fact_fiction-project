Either way the idea is that
each component contributing to the computation of the estimate will have independent or semi-
independent estimates based on having been exposed to different subsets of data or states of the
environment and possibly having a different computational capacity. This is a variant of a wisdom
of crowds type argument. The fact, however, that integrating over many estimates can yield a
better overall estimate is a somewhat trivial insight and not, in my mind, where the interesting
issues lie. Interesting questions concern the details of the aggregation portion of the collective
computation itself (see also [43]). In other words, what are properties of the collective
computation allow it to produce ‘good’ estimates [11,26,27,44]?