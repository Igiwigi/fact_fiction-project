They therefore conclude that grid
cells, in both biological systems and machines, ‘furnish
agents with a Euclidean spatial metric’.

...we argue that grid-like representations furnish agents with a

Euclidean geometric framework — paralleling the proposed com-

putational role in mammals as an early developing Kantian-like

spatial scaffold that serves to organize perceptual experience...

(From Banino et al. [216].)

Non-Euclidean: By contrast, at our meeting and in [220], Ida
Momennejad argues that it’s the non-Euclidean aspects of
place and grid cells that need accounting for, such as the distor-
tions of grid cell firing fields by rewards, as well as the fact that

the majority of distance estimates in the hippocampus reflect
path distance (taking into account obstacles) rather than
direct Euclidean distance [221,222]. Reinforcement learning has been proposed as a way
of capturing these non-Euclidean properties of place and
grid cells. Gustafson & Daw [223] argue that an emphasis
on path rather than Euclidean distance reflects the fact that
place and grid cells ‘are well adapted to support reinforce-
ment learning’, since efficient reinforcement learning
requires that the inputs (place and grid cells) are already
articulated in terms of the goals of navigation:

Importantly, this exercise views the brain’s spatial codes less as a

representation for location per se, and instead [as] a value function

over state space — a mapping of location to value. More recently, Stachenfeld et al. [224,225] argue that place cells
are the encoding of ‘successor representations’. In reinforce-
ment learning, ‘successor representations’ [226] provide a
model of next steps, affording the flexibility of considering
alternatives at each stage (versus model-free reinforcement
learning), while avoiding the computational intractability of
modelling the whole world (model-based reinforcement learn-
ing).