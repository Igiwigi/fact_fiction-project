recorded the signals the sender produced, the context in dataset and then used to predict a test dataset. Given the
which they were used and the reaction of the receiver. size of the dataset we had available, this approach was not
More specifically, they coded the type of manual gesture possible here. The code that spells out the model architecture
using a form-based coding scheme, differentiating between and the processing algorithms and that can be used to repro-
morphological configurations of the joints of the arm, hand duce the results is available in the associated online
and fingers. Using this procedure, they identified two fre- repository: https: //github.com/manuelbohn/RSApes.
quently occurring gesture types: stretched-arm, consisting of Based on the model and the parameter settings, we gen-
an extended arm with both the arm and hand stretched, erated predictions for all possible combinations of gestures,
and bent-arm, with either hand or forearm bent and the facial expression, dominance relationship and social context.
back of the hand or arm directed at the receiver. Facial We compared these predictions to the observations made
expressions were coded using a modified version of the by Ofa ef al. [50]. Our model makes predictions about the

human Facial Action Coding Scheme (FACS) [78] developed receiver's interpretation of the utterance in context. The


(a) (b)

bared hoot neutral 1.00 T
1.00 x r=0.84 “
ow
0.75 f 2 ° @ T
0.50 ql :
g 025 3 “ observations
3 sl reactiontype 3 10
eo miye 3 050 bd