‘that the values of L may serve as a measure of our uncertainty or confidence in the
“torresponding values of the Os. Accordingly, we should have the greatest con-
“idence in the values, say, 9,, 9, ... 9,, forwhich Lis a maximum. 9; obviously is
<A function of x’,...x',; it is called the maximum likelihood estimate of 6;.
5 As far as I am aware, the idea of the maximum likelihood estimates is due to
‘Kart Pearson, who applied the principle in 1895 (see particularly pp. 262-265),
“among others to deduce the now familiar formula for estimating the coefficient of
‘orrelation. However, he did not insist much on the general applicability of the
Sprinciple. This was done with great emphasis by R. A. FisHer, who invented the
‘Berm likelihood, and in a series of papers (FisHeR, 1925) stated several important
a roperties of the maximum likelihood estimates, to the general effect that it is
amprobable that their values will differ very much from those of the parameters
stimated. In fact, the maximum likelihood estimates appear to be what could be
Galled the best “ almost unbiassed ”’ estimates. Many of Fisuer’s statements, partly
n a modified form, were subsequently proved by Horetuine (1932), Doos (1934),
and Ducus (1936). An excellent account of the present state of the theory is given
by Darmors (1936). . : :
3 In certain cases the unbiassed estimates are identical with those of maximum
ikelihood ; in others we know only the maximum likelihood estimate, and then
Fac is no “ competition ” between the two principles. But it sometimes happens
nd lead to different results. Such is, for instance,

Ah inci be applied a:
eee renal oS See are all independent and each of them
