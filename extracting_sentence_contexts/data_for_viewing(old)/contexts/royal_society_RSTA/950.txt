robots may ‘inhabit’ a company and ‘thereby gain some of the incidents of legal personality’ [19].

Yet, the idea of Al robots ‘just like corporations’ has been strongly opposed by others, including
the open letter of several ‘Artificial Intelligence and Robotics Experts’ in April 2018. Granting
robots the status of legal persons just like corporations would indeed be a terrible mistake.
According to this narrative, if AI robots were ‘electronic persons responsible for making good any
damage they may cause’, in the phrasing of the EU Parliament's resolution from 2017, we should
be ready to tackle ‘two kinds of abuse that might arise at the expense of human legal rights—
humans using robots to insulate themselves from liability and robots themselves unaccountably
violating human legal rights’ [3, p. 285]. In the first case, the agenthood of artificial agents could
be a means to shield humans from the consequences of their conduct. Damages provoked by the
behaviour and decisions of AI systems would not be upon the fat cats of Silicon Valley, because
only an AI system would in fact be liable. In the second case, we should expect cases of robot
insolvency: ‘money can flow out of accounts just as easily as it can flow in; once the account is
depleted, the robot would effectively be unanswerable for violating human legal rights’ [3, p.
288]. Traditional punitive sanctions of the law, such as jail time for criminal insolvency, would be
unavailable, unsatisfying or ineffective. On this basis, we may envisage the malfunctioning of AI
robots or their manipulation that cause or fuel human wrongdoing, if not properly detected and
recovered, therefore making people vulnerable to systematic recourse to such artificial agents.

Still, there are three problems with this kind of narrative on robots ‘just like corporations’. First,
the corporate solution for the legal agenthood of AI robots is only one among several technical
options that scholars have suggested over the past years. The list of models proposed by the
‘Artificial Intelligence and Robotics Experts’ in their letter from April 2018 is incomplete. There is
no such a simple alternative between the ‘Legal Entity model’ and the ‘Anglo-Saxon Trust model’.