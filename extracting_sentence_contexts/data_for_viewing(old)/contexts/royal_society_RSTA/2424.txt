weights are usually set at random and remain fixed during both training and operation. This
makes the learning phase of RC much more computationally efficient than in RNN (since learning
is reduced to a linear regression problem in RC). In many situations, the effective computational


power of RC has been found comparable, or in some cases even better than, their standard RNN
counterpart.

One major technological challenge of neuromorphic computing is however to imagine and
design a physical hardware implementing its specific concepts, instead of translating them into
algorithms to be programmed in standard, however structurally unmatched, digital processors.
The generally recognized poor energy efficiency of artificial intelligence (involving dedicated
supercomputers, or energy greedy computer farms) is indeed related to the fact that brain
computing concepts have to be adapted into Turing von Neumann machines, whose architecture
and principles of operation are actually very far from what we have learned from the brain.
Up to now, there is essentially no other easily available and dedicated computing platform
capable of efficiently running artificial intelligence techniques. Turing von Neumann machines
are practically the only effectively working solution today for investigating AI.

An essential problem when one wants to design a dedicated hardware implementation of
neural network processing concepts is the difficulty to physically fabricate a well-controlled three-

dimensional dynamical network, as nature easily does with any brain. Based on the assumption : =
that what matter are the dynamical complexity and the high phase space dimension, but not : =
the internal structure itself of the reservoir network, the EU project PHOCUS (PHOtonic liquid 13