Non-Euclidean: By contrast, at our meeting and in [220], Ida
Momennejad argues that it’s the non-Euclidean aspects of
place and grid cells that need accounting for, such as the distor-
tions of grid cell firing fields by rewards, as well as the fact that

the majority of distance estimates in the hippocampus reflect
path distance (taking into account obstacles) rather than
direct Euclidean distance [221,222].

Reinforcement learning has been proposed as a way
of capturing these non-Euclidean properties of place and
grid cells. Gustafson & Daw [223] argue that an emphasis
on path rather than Euclidean distance reflects the fact that
place and grid cells ‘are well adapted to support reinforce-
ment learning’, since efficient reinforcement learning
requires that the inputs (place and grid cells) are already
articulated in terms of the goals of navigation:

Importantly, this exercise views the brain’s spatial codes less as a

representation for location per se, and instead [as] a value function

over state space — a mapping of location to value.

More recently, Stachenfeld et al. [224,225] argue that place cells