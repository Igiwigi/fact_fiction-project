least where public authorities act in the exercise of public power, the simple reality is programs
of AI which do not give reasons and the decisions of which can also not be explained by humans
cannot be used in the exercise of public power, as by using such programs, the public authority
could not fulfil its obligation to state reasons.°”

A new intensity of three-level impact assessment of technology is a necessary component of a
new intensity of the dialogue between technology and democracy which is vital at a time when
we are entering a world in which technologies like AI become all-pervasive and are actually
incorporating and executing the rules according to which we live in large part.

AI will in many areas of life decide or prepare decisions or choices which previously were
made by humans, according to certain rules. If thus AI now incorporates the rules according
to which we live and executes them, we will need to get used to the fact that AI must always
be treated like the law itself. And for a law, it is normal to be checked against higher law, and
against the basic tenants of constitutional democracy. The test every law must go through is
whether it is in line with fundamental rights, whether it is not in contradiction with the principle
of democracy, thus in particular whether it has been adopted in a legitimate procedure, and
whether it complies with the principle of the rule of law, thus is not in contradiction to other
pre-existing law, sufficiently clear and proportional to the purpose pursued. It is this test which
AI that incorporates rules for society and applies them through decisions or the preparation of
decisions must also go through. And AI will only pass this test if by design, the principles of
democracy, rule of law and compliance with fundamental rights are incorporated in AI, thus
from the outset of program development.

In the same way that an architect from the outset of designing a house has to think of