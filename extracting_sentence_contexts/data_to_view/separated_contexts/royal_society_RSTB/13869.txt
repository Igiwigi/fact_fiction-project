Here, the device visually filters out a dog aggressively barking at the child, directly in the child’s mind. (Online version in
colour.)

difficult to trust whether the smiles, laughs and frowns of create opportunities for highly desirable situations. First, the
our conversation partners are genuine or algorithmically fact that, e.g. a smiling voice transformation can be used to
modulated (figure 1c). appear happier than one really is becomes highly desirable
The goal of this paper is to initiate the data-driven study in the case of patients who cannot easily express emotions
of expressive deep-fakes ethics (specifically here, vocal deep- (e.g. amyotrophic lateral sclerosis patients who rely on assis-
fakes) and, inspired by the methodology of ‘experimental tive voice technology for communication, [22]). Second, the
ethics’ [16], to quantify societal expectations about the fact that voice or face transformations can coerce observers
principles that should guide their deployment. into subsequent actions can be desirable in interventions
The realistic, artificial manipulation of expressive behav- where people are nudged into positive behaviour [23], for
iour raises unprecedented societal and ethical questions. instance reducing aggressive behaviour in call-centre conver-
First, it raises concerns about truthfulness. Because expressive sations by transforming the operator's fatigued voice [24], or
behaviours are often thought to provide genuine cues about applying a gender voice transformation on an online hiring
the sender’s emotional states [17], the ability to arbitrarily platform to alleviate gender biases [21] (figure 2, top). Third,
manipulate these displays opens avenues for deception: one the fact that expressive transformations can be processed
may use, e.g. a facial filter to fake a smile despite having no unconsciously may be desirable in situations where this
intent to affiliate, or a voice transformation to appear more increases their effectiveness, as seen in emotional vocal
certain than one really is.