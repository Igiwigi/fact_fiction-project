activation pattern (figure 5¢,). Once weights have converged
to one of the respective stable states, they keep fluctuating,
but do not change on average. As the RCPs do not impose
a single set point, activity patterns are not unlearned when
a certain input is kept active (inactive) for extended periods
of time (compare figure 5d with 5¢,h).

As a result, neuron 2 shown in figure 5h shows ‘no learn-
ing’ which seems undesirable at first. However, it is in fact
useful for such a stable equilibrium to exist when learning
is considered as a network phenomenon. Other neurons
(neuron 1 in our case) already are selective and code for a
given stimulus. Analogously, neuron 2 might in fact code
for a different stimulus which is not active at the moment,
in which case we would like to perturb it as little as possible
while other neurons ‘learn’ (figure 5/). Similar dynamics can
be achieved in learning models with strong lateral inhibition
which completely suppresses neuronal activity and thus
also associative plasticity. In the present scenario, however,
this is not the case. Neuron 2 is still firing with some low
background activity throughout (figure 5f).

There are several aspects worth noting about the model.
First, heterosynaptic plasticity not only stabilizes Hebbian
plasticity in the active pathway, it also introduces synaptic