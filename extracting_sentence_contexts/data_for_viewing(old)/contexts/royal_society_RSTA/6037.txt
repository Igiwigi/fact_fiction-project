PUBLISHING


This article is part of the theme issue ‘Emergent phenomena in complex physical and socio-
technical systems: from cells to societies’.

]. Introduction

When the first superhuman computer program in the game of Go—AlphaGo—beat the world
champion Lee Sedol in 2016, its gameplay was considered surprising and unconventional,
apparently violating longstanding Go traditions. In particular, for move 37, AlphaGo calculated
the chance of a human player making the same move as 1 in 10000 [1]. Its unconventional play
likely originated from the fact that AlphaGo, and more so its successor AlphaGo Zero [2,3],
learned through self-play with little or no reliance on human historic gameplay. The performance
of AlphaGo raises the question of how such novel gameplay would influence human strategies
[1]. Replaying historic human matches of the last 300 years showed that an algorithm similar to
AlphaGo Zero increasingly often chooses the same move as humans [4], indicating convergence
towards a common gameplay. Remarkably, there has been a steep increase in this alignment
since 2017 when such an algorithm became available to the public [4,5]. These observations
suggest the fascinating hypothesis that increased alignment is the result of a hybrid form of social
learning, where AI solutions are copied and maintained by humans. Similar patterns of increased
alignment between human and algorithmic play have been suggested in the game of chess [6].

The use of technology, such as books or software, for human training in games like Go and
chess is not a novel phenomenon and represents a common method of socially transmitting