expressions—for example, generating navigation instructions
or referring to a particular object or location in the world.
Referring expression generation is possibly the most
thoroughly studied topic in NLG, perhaps primarily because
it is one where both the input and the output are relatively
straightforward to define (unlike many other, more open-
ended tasks such as generating text with a particular style
or generating persuasive text). The generation of situated
references was the topic of the series of successful NLG
shared tasks collectively called the GIVE challenges [46],
where researchers competed to develop systems that were
able to generate instructions to move around and interact
with objects in a virtual, maze-like world. In fact, this is
one area where social robotics researchers do tend to adopt
similar techniques for output generation (e.g. [11,47]).

However, most social robot interactions involve much
more than referring to world objects and filling slots for data-
base queries [48]: they involve interactions situated in the real
world, where the output of the robot should include both
coverage of diverse topics as well as appropriate situated
multimodal behaviour—obviously including linguistic con-
tent, but also incorporating non-verbal behaviours such as
prosody and gesture. For example, in the MuMMER project
[2], the goal is to place a Pepper robot in a shopping mall