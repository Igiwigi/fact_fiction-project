We exposed the model to sequences containing embedded
pairs. There were eight items (A—H) grouped into four pairs
(AB, CD, EF, GH). Items within a pair always occurred in a
fixed order but the sequence of pairs was random. Specifically,
the second item in a pair could transition to the first item in one
of the three other pairs. Back-to-back repetitions of a pair were
excluded, since this is acommon constraint in statistical learn-
ing experiments and because allowing repetitions would dilute
the temporal asymmetry (both AB and BA would be exposed).
There was a moving window of two stimuli presented at a time.
After AB, for example, BC, BE, or BG followed with equal prob-
ability; if BC was chosen, the next input would be CD. To detect
regularities, the model had to be sensitive to the fact that, over
time, pairs (e.g. AB) occurred more often than sets of two items
spanning pairs (e.g. BC). To contrast this learning challenge
with a more ‘episodic’ situation with demarcated events, we
also ran simulations where pairs were presented in interleaved
order, with no transitions between pairs. In other words, AB,
CD, EF, and GH all appeared but never BC or FG, for example.
Note that we will use A and B to refer to the first member and
second member of a pair, respectively. All results are averaged
across the four pairs.

Different representations emerged in the model for
sequences that did versus did not require sensitivity to statistics