were the true C’s; call these calculated proportions A,, As, ...A,. The differences
between these “calculated” A’s and the “observed ” a’s are the “ discrepancies ” of
the a’s. Now if we took a random sample of N from a large population falling into
two categories in which the numbers were proportional to A, and 1 — A, respectively,
and if the numbers actually taken were Na, and N (1 —a,), the mean value of N a,—NA
would be 0, and its s.d.* would be {NA, (1 — A,)}*. The ratio of the actual value of
Na, — NA, to its s.d. can be found for each of the m values of f; and we can see whether
the distribution of these ratios is such as might reasonably be due to random sampling
from a set of ratios with mean value 0 and standard deviation 1.

The imperfections of this method are as follows :-—

(A) We take no account of the fact that by finding the ©’s from the a’s we have
already to some extent fitted the hypothetical formula to the data, and that an approxi-
mate agreement between the deduced values and the data must, to this extent, be
fallacious. If, to take an extreme case, were = m, so that we used a formula with
just as many C’s as a’s, the discrepancies would all be 0: but this would prove nothing
as to the suitability of the formula. Another way of stating the matter is that we
compare each discrepancy, not with its own s.d., but with the s.d. of the true error.

* Abbreviations.—m.p. = mean product ; m.p.e. = mean product of errors; m.s,= mean square ;
. 5 -
m.s.c, = mean square of error; s.d. == standard deviation.

