We pause at this juncture in the ever-vigorous progress of Will the reader or listener or discussant be able to infer the pat-
scientific and philosophical investigation into the nature of tern of relations between units? If so, how? Is there an optimal
mind and reality. We focus our attention on the networked mapping of the network into a stream that supports rapid
nature of knowledge as well as the networked nature of the inference on the part of the receiver or interlocutor?

computational unit—the brain—that allows the human mind
to process and construct that knowledge. Wereview recent evic (a) Statistical lea rning and the relevance of
dence for network constraints on learnability of information

and network constraints on the architecture of neural circuits transition probabilities

that support that learning. We discuss similarities in those con- Broadly, the problem of inferring patterns of pairwise depen-
straints and attempt to reason about why there might exist a dencies from incoming streams of data is in fact much more


general than simply listening to a lecture or engaging in a between two stimuli; from the type of walk (random, Eulerian El

discussion. Indeed, the capacity to make such inferences and Hamiltonian), the investigators were able to determine

allows us to learn language [28], segment visual events [3], that the manner in which the network was traversed impacted S
parse tonal groupings [4], parse spatial scenes [5,29], infer human expectations. Second, the field needed a clear demon- z
social networks [6,30] and perceive distinct concepts stration that human expectations could be manipulated =
7,8,31,32]. The underlying general learning mechanism is differently by different network architectures. Kahn and S
known as statistical learning, which can be defined as the ability colleagues studied human expectations derived from a = =
for humans and other animals to extract statistical regularities stream of stimuli drawn from a random walk on three different S