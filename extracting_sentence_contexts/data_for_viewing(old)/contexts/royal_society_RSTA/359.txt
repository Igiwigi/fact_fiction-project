
We can think of all models as information channels from past data D to future predictions x.
The parameters in a parametric model constitute a bottleneck in this information channel. The
complexity of the model, and the capacity of the channel, is bounded, even if the amount of
observed data becomes unbounded. Parametric models are therefore not generally very flexible.

By contrast, a non-parametric model assumes that the data distribution cannot be defined in
terms of such a finite set of parameters. However, often we can think of non-parametric models
as being defined in terms of an infinite-dimensional 6. More formally, the infinite-dimensional


6 is often represented as a function. The term non-parametric is therefore a bit of a misnomer;
it is not that non-parametric models do not have parameters; in fact, they have infinitely many
parameters. Because of this, non-parametric models cannot be explicitly represented in terms of
their parameters.

From the information channel viewpoint, we have removed the bottleneck. The amount of
information that @ can capture about the data D grows as the amount of data grows. This makes
non-parametric models more flexible than parametric models.Â°

There is another way to view the difference between parametric and non-parametric models.
Predictions from a parametric model are explicitly and compactly summarized through the
parameters 0, P(x|). Non-parametric models, by contrast, cannot be summarized in this way.
Because of this, predictions from a non-parametric are necessarily memory-based, P(x|D); to make
predictions, we need to store or remember a growing amount of information about the training