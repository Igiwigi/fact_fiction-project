cov(s}, 57) = E(s?s;} - E(s;}E(s;} >0. (6.3)

The extensions of ICA with correlations of squares essentially differ in what kind of
dependencies they assume for the variance variables v;. In the earliest work, the vj were divided
into groups (or subspaces) such that the variables in the same group are positively correlated,
while the variables in different groups are independent [39]. A follow-up paper made this division
smooth so that the dependencies follow a ‘topographic’ arrangement on a two-dimensional
grid, which allows for easy visualization and has interesting neuroscientific interpretations [40].
A fixed-point algorithm for the subspace model was proposed by Hyvarinen & Koster [41].

In those early models, the dependency structure of the v; is fixed a priori (but see the extension
by Gruber et al. [42]). In more recent work, the dependency structure of the v; has been estimated
from data. The model in Hyvarinen et al. [40] in fact contains a parameter matrix that describes
the correlations between the v;, and one can estimate these parameters rather straightforwardly
[43]. A closely related formalism uses a generative model of the whole covariance structure of x
[44,45].


Another line of work defines a parametrized pdf that does not have an explicit representation
of the variance variables v; but attempts to model the same kind of dependencies [46,47]. The pdf
is typically of the form

log p(x) = > G (= is?) + log Z(H), (6.4)
J
