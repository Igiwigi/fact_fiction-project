computation [57], the output provided by TSQR can be identical to the output provided by
a conventional algorithm as implemented in LAPACK. Speed-ups resulting from using these
communication avoiding algorithms are reported in [57], for example.

While direct methods in dense linear algebra are well-understood today from a
communication complexity point of view, deriving lower bounds on communication for sparse
matrices is a much harder problem, for both iterative and direct methods. It is possible to
apply directly the bounds derived for dense matrices to direct methods involving matrices with
arbitrary sparsity structure, but in general, these bounds can become vacuous. A few results exist,
though, for matrices with specific sparsity structures. Tight lower bounds on communication for
the sparse Cholesky factorization of a model problem are derived in [58], and the multiplication
of Erdés-Rényi matrices is discussed in [59]. Reducing communication in iterative methods is a
challenging topic, with an additional difficulty being the fact that the convergence of iterative
methods depends on the spectral properties of the matrices involved. Approaches such as s-step
methods (e.g. [60,61] and the references therein) or enlarged Krylov methods [62,63] are actively
investigated.

Many open questions remain to be addressed beyond linear algebra. In a general setting,
the problem to tackle is the following. Given an algorithm based on multiple nested loops
that reference arrays with different dimensions, the goal is to identify lower bounds on
communication for this algorithm, and subsequently an optimal loop tiling that allows those
bounds to be attained. Results along this direction are presented in [64] and they are based
on the discrete multilinear Holder-Brascamp-Lieb (HBL) inequalities. The polyhedral model
used in the compiler community is another approach for reorganizing nested loops to reduce
data movement, and there might be interesting connections between the two approaches.