constructed, which we call the s-time conditional PDF, the full dynamics can be obtained.

For Markov systems only the most recent observation defines the dynamics in the future,
therefore Qi); = Qi)1. For such cases, equation (2.5) implies that

times
eee
Prgangay trgar << X1,b) = Qty nga, bra Xn tn) « - - Q1y1 %2, #211, #1) Pi (x1, f)- (2.6)

Since, with x’ being any one of the independent variables x; inside P,,,1, we have P;, = f Pry dx’,
that is P, is the marginal of P,,,;, Markov processes are completely characterized once P is
known as Qi); = P2/P}. This is not the case for non-Markov processes for which it is necessary to
find all Qijs = Ps41/Ps for all s. This fact is in general true except for certain linear non-Markov
systems, for example the class of linear Gaussian processes discussed below, for which it is
possible to determine any P,.

At the level of the Langevin equation, the distinction between Markov and non-Markov
systems can be explained pictorially with figure 1, where we display two hypothetical systems,
a Markov and a non-Markov one, whose state variable x are prepared localized at x =5xo. At
time t = s, both systems are observed for the first time at location x = xo indicated by the spatial
coincidence of all sampled trajectories at time f = s. The dynamics of interest are those for which
t>s and, depending on the system being Markov or not, prediction abilities may differ. The
different colouring scheme of the non-Markov and Markov cases for f <s points to the history
dependence of the former versus the latter. For a Markov process, the actual trajectory followed
to reach x = x9 is irrelevant for the subsequent dynamics. All that matters is the first observation