machine learning to predict vertical profiles of longwave [8-13] and shortwave [10,11,13]
radiative fluxes in weather and climate models. These end-to-end approaches, i.e. predicting
radiative fluxes by fully emulating a radiative transfer scheme, may result in speed-ups of
more than one order of magnitude [8,9,11], with root mean squared errors (MSEs) of the
heating rates within 0.2Kd7! for shortwave and 0.5Kd7! for longwave radiation. However,
such an approach is inflexible with respect to changes in model configuration including
the vertical discretization as the neural networks are trained for a fixed number of vertical
layers [8-11]. Moreover, this approach does not respect the well-understood underlying
physics.

In this study, we describe a machine learning approach for accelerating radiative transfer
computations that respects the well-understood governing equations, using machine learning
only to accelerate the data-driven aspects of the calculations. We exploit the fact that radiation
calculations are composed for two distinct steps: the mapping of the physical and chemical
state of the atmosphere to a problem in radiative transfer and the subsequent solution of that
radiative transfer problem. The first step converts temperature, pressure and composition into
atmospheric optical properties that determine how much radiation is emitted (Planck source
function), absorbed or scattered (optical depth, single scattering albedo), and the direction of
scattering (asymmetry parameter). Unlike the solution of the radiative transfer equation, the
calculation of gas optics relies on empiricism and large amounts of tabulated data.

Here, we use machine learning to emulate the calculation of gaseous optical properties of a
modern RRTM for general circulation model applicationsâ€”parallel (RRTMGP) [14]. We use neural
networks as a computationally efficient tool to replace the lookup-tables used in RRTMGP and
train the networks for a narrowed range of atmospheric conditions, e.g. by neglecting variations