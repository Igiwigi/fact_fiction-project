tortions are not incompatible with MB-HRL, because it is nowhere
stipulated in the MB-HRL framework that the agent’s internal
model must necessarily be accurate. At the same time, it should


also be noted that, even when the model is inaccurate, it may still be Botvinick et al. [10], again using the same parameter values. | 8 |

of use due to the enormous computational savings that arise from Once again, the set-up was treated as model-based in the

temporal abstraction. . - .
P sense that action outcomes were viewed as coming from the = 4

There is, in fact, a fundamental connection between option dis- . . . a
covery based on prediction and option discovery based on causal agent's internal transition model, rather than from the environ- ©
dependencies. For a discussion of the relationship between the two, ment itself. In order to implement saltatory MB-HRL, the same a
see [57]. simulation code was employed, but the count of steps taken = 2
was not incremented during execution of option policies. Ss
. This approach simulated a scenario in which the agent hed | =|
Appendix A an accurate model for each option and sampled from its tran- =
Here, we briefly describe the methods employed in the sition, duration and cost distributions in generating plan 2
simulation illustrated in figure 2. trajectories.
The flat RL agent was implemented using a standard To implement memory limitations, it was assumed that 2
actor—critic architecture, following the same approach as each agent had a 10% chance on each step of ‘losing track’ *
described in Botvinick et al. [10], and using the parameter of which state was to be sampled. This event was understood 5
values specified in that source. In order to realize the actor— as triggering an immediate termination of the planning trial 2