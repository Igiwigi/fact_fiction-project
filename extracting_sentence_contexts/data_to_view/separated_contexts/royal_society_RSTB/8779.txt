Arbitrating between adjusting the cur-
predictive models serve as action and outcome predictors, rent actor versus creating a new one thus yields to a decision
respectively, for implementing covert RL, whereby outcome between model-based and model-free RL, which accounts for
rewarding values are possibly altered with respect to current behavioural changes observed in rodents (e.g. extinction
animal needs (e.g. satiety effects). This model-based RL process effects) following outcome devaluation manipulations [20].
calibrates the new actor selective model according to current As generally agreed, the premotor cortex along with the
animal needs. dorsal striatum encodes and stores selective models of behav-
As the new actor is created from the strategies repertoire, ioural strategies [26-28], whereas the dorsal and ventral
its initial absolute reliability corresponds to the repertoire striatum implement RL adjusting the actor selective model
absolute reliability, ie. the probability the current external (see above). Our hypothesis is that operating beyond RL, the
contingencies match those associated with one stored strat- factual and reactive inferential system is implemented in para-
egy, or equivalently, the probability that the animal faces a limbic prefrontal regions (figure 1, right). The OFC (especially
previously encountered situation. This absolute reliability is the medial OFC in humans) encodes strategies’ predictive
inferred using Bayes’ law, which requires evaluating the like- models and updates actor absolute reliability according to
lihood of the current action outcome in every previously action outcomes.