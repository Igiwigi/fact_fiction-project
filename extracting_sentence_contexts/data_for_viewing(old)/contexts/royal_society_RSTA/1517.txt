of radar data is particularly challenging due to the double penalty problem (cf. [116,120]). Indeed,
verification of precipitation forecasts is still a hot topic in the meteorological community [121].
The evaluation of extreme events suffers from the ‘forecaster’s dilemma’, which discredits skilful
forecasts when they are evaluated only under the condition that an extreme event occurred.
This conditioning on outcomes and observations violates the theoretical assumptions of forecast
verification methods [21,122].

6. Physical constraints and consistency

As has been demonstrated in other application areas of ML (e.g. [123,124]), NNs can be prone
to learning spurious relationships in data. A purely data-driven model for weather forecasting
might fail to adhere to the underlying physical principles and thus generate false forecasts as
it lacks understanding of the fact that every atmospheric process obeys physical laws described
in terms of conservation of momentum, enthalpy and mass. The incorporation of physical laws
in NNs is becoming a vibrant area of research (e.g. [125-128]) and is now often denoted as
scientific ML.

One of the first studies to demonstrate that physical constraints can efficiently reduce
systematic biases in lake temperature predictions, while at the same time enhancing
generalization capability, was Karpatne et al. [129]. They included numerical model results as
constraints for sparse observations and added a loss term to punish non-physical behaviour of
the DL model. De Bézenac et al. [127] embedded an advection diffusion equation in their loss
function to predict sea surface temperatures and thereby improved the predictive capabilities of
their model. Le Guen et al. [76] introduced a new two-stream model and a recurrent cell, which
is based on concepts from DA. The cell includes a physical predictor and a Kalman filter in order