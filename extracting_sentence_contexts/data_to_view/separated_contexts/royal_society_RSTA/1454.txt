Lewis appears apposite: ‘When man proclaims conquest of
power of nature, what it really means is conquest of power of some men over other men’. When
social media hit at human weaknesses, such as the desperate need for fame through a growing
list of ‘followers’, collecting money for the disaster brought about by a tsunami, good as it is, does
not change the final balance sheet: mankind loses anyway. A similar story applies to the big claims that cross the border into big lies, such as the promises
of the so-called Master Algorithm, allegedly capable of extracting all the information from the data,
doing everything, just everything we want, even before we ask for it [14]°

In this essay, we hope we have made it clear why some of the boldest claims of BD are in fact
little or nothing short of big lies, that is:

(i) Complex systems support uncertainty to a much stronger degree than the Law of Large
Numbers (Gaussian statistics) would have us believe. The implication is that error decay
with data volume is considerably slower, to the point of becoming impractically slow
even in the face of zettabytes;

(ii) No system is infinite, but when operating to their maximal extent, complex systems
support the onset of competitive interactions, in turn leading to data conflicts, which
may either saturate the return on investment (in terms of the information gained per unit
of data) or even make it negative by supplying more data than a finite-capacity system
can process. Those BD aficionados who promise us ‘all we want and more’ simply choose
to ignore this, and it is not hard to see why.

(iii) In the end, most of BD comes down to more or less sophisticated forms of curve
fitting based on error minimization.