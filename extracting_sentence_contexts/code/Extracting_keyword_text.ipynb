{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets contexts for each keyword of interest\n",
    "(can speed this up by having it write the files as it runs, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "import spacy\n",
    "\n",
    "#might be a bit redundant to have both spacy and nltk, but can easily switch between them when testing (and remove one later)\n",
    "#spacy is better at splitting into sentences, but much slower performance\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    nlp.max_length = 3_000_000 #set a different max to accom. longer docs\n",
    "except OSError:\n",
    "    print(\"Downloading spaCy model 'en_core_web_sm'...\")\n",
    "    os.system(\"python -m spacy download en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "class TextContextExtractor:\n",
    "    def __init__(self, keywords, sentences_before, sentences_after, newest_year_included=1950, skip_after_specific_year=True, use_spacy=False, \n",
    "                  create_excel=True):\n",
    "        self.keywords = [kw.strip() for kw in keywords]\n",
    "        self.sentences_before = sentences_before #how many sentences before are counted\n",
    "        self.sentences_after = sentences_after #how many sentences after are counted\n",
    "        self.use_spacy = use_spacy #if not, uses nltk\n",
    "        self.newest_year_included = newest_year_included\n",
    "        self.create_excel = create_excel\n",
    "        self.skip_after_specific_year = skip_after_specific_year\n",
    "        \n",
    "        self.keyword_patterns = [\n",
    "            (kw, re.compile(r'\\b' + re.escape(kw) + r'\\b', flags=re.IGNORECASE))\n",
    "            for kw in self.keywords\n",
    "        ]\n",
    "\n",
    "    def extract_text_from_txt(self, txt_path):\n",
    "        \"\"\"Extract text from a given TXT file.\"\"\"\n",
    "        with open(txt_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "\n",
    "    def _tokenize_sentences(self, text):\n",
    "        \"\"\"Tokenize text into sentences using either spaCy or NLTK.\"\"\"\n",
    "        if self.use_spacy:\n",
    "            doc = nlp(text)\n",
    "            sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "        else: #nltk\n",
    "            sentences = nltk.tokenize.sent_tokenize(text, language='english')\n",
    "            sentences = [sent.strip() for sent in sentences if sent.strip()]\n",
    "        return sentences\n",
    "\n",
    "    def _get_context_window(self, sentences, match_idx):\n",
    "        \"\"\"Extract a window of sentences around a matched keyword.\"\"\"\n",
    "        start_idx = max(0, match_idx - self.sentences_before)\n",
    "        end_idx = min(len(sentences), match_idx + 1 + self.sentences_after)\n",
    "        context_sentences = sentences[start_idx:end_idx]\n",
    "        return ' '.join(context_sentences)\n",
    "\n",
    "    def find_contexts(self, text):\n",
    "        \"\"\"\n",
    "        Extracts contextual snippets around specified keywords within a text. \n",
    "\n",
    "        How it works:\n",
    "        1. Splits the input text into sentences using either spaCy or NLTK tokenization.\n",
    "        2. Iterates over each keyword defined in keywords.\n",
    "        3. For each keyword, searches all sentences for matches (case-insensitive, \n",
    "        and matching whole words only to avoid partial matches).\n",
    "        4. When a keyword is found, selects a range of sentences around it:\n",
    "        - `sentences_before` sentences before the keyword sentence\n",
    "        - `sentences_after` sentences after the keyword sentence\n",
    "        5. Joins these sentences together into a single context snippet and stores \n",
    "        it along with the keyword.\n",
    "        \n",
    "        Returns:\n",
    "            A list of tuples: [(keyword1, context1), (keyword2, context2), ...]\n",
    "            Each tuple contains the keyword and the extracted context surrounding it.\n",
    "        \"\"\"\n",
    "        contexts = []\n",
    "        sentences = self._tokenize_sentences(text)\n",
    "        \n",
    "        for keyword, pattern in self.keyword_patterns:\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                if pattern.search(sentence):\n",
    "                    context = self._get_context_window(sentences, i)\n",
    "                    contexts.append((keyword, context))\n",
    "        return contexts\n",
    "\n",
    "    def save_contexts_to_csv(self, contexts, output_path):\n",
    "        \"\"\"Save extracted contexts to a CSV file.\"\"\"\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        with open(output_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Filename\", \"Keyword\", \"Context\", \"Author\", \"Title\", \"Date\"])\n",
    "            writer.writerows(contexts)\n",
    "\n",
    "    def _format_as_text(self, value):\n",
    "        \"\"\"Ensure that the text is formatted as plain text in Excel.\"\"\"\n",
    "        if isinstance(value, str) and value.startswith('='):\n",
    "            return f\"'{value}\"\n",
    "        return value\n",
    "\n",
    "    def convert_csv_to_excel(self, input_csv, output_excel):\n",
    "        \"\"\"\n",
    "        Convert a CSV file to an Excel file, ensuring that context text is formatted as plain text in Excel.\n",
    "       \n",
    "        Parameters:\n",
    "        - input_csv (str): Path to the input CSV file.\n",
    "        - output_excel (str): Path to the output Excel file.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(input_csv)\n",
    "        df['Context'] = df['Context'].apply(self._format_as_text)\n",
    "        \n",
    "        # Ensure the output directory exists\n",
    "        os.makedirs(os.path.dirname(output_excel), exist_ok=True)\n",
    "       \n",
    "        df.to_excel(output_excel, index=False, engine='xlsxwriter')\n",
    "\n",
    "    def load_metadata_csv(self, metadata_path):\n",
    "        \"\"\"Load metadata from a CSV file into a dictionary.\"\"\"\n",
    "        metadata = {}\n",
    "        with open(metadata_path, mode='r', newline='', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                if 'filename' in row:\n",
    "                    file_location = row['filename']\n",
    "                else:\n",
    "                    file_location = row.get('pdf_link', '').split('/')[-1]\n",
    "                \n",
    "                base_name = os.path.splitext(file_location)[0]\n",
    "                metadata[file_location] = row\n",
    "                metadata[base_name + '.txt'] = row\n",
    "                metadata[base_name + '.pdf'] = row\n",
    "        return metadata\n",
    "\n",
    "    def _get_file_metadata(self, metadata, filename):\n",
    "        \"\"\"Get metadata for a file, trying multiple filename formats.\"\"\"\n",
    "        #messy way of getting the pdf_filename between diff types of metadata\n",
    "        #could be improved but works for now\n",
    "        \n",
    "        if filename in metadata:\n",
    "            return metadata[filename]\n",
    "        \n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        pdf_filename = base_name + \".pdf\"\n",
    "        txt_filename = base_name + \".txt\"\n",
    "        \n",
    "        if pdf_filename in metadata:\n",
    "            return metadata[pdf_filename]\n",
    "        elif txt_filename in metadata:\n",
    "            return metadata[txt_filename]\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def _should_skip_by_year(self, date):\n",
    "        \"\"\"Check if a file should be skipped based on its year.\"\"\"\n",
    "        year_match = re.search(r'\\d{4}', str(date))\n",
    "        if year_match:\n",
    "            year = int(year_match.group())\n",
    "            if year > self.newest_year_included:\n",
    "                #print(f\"{filename} article, year {year}, is too new to be of interest (newer than year:{newest_year_included})\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _create_excel_path(self, output_csv):\n",
    "        \"\"\"Generate the Excel output path in the excel_ver subfolder.\"\"\"\n",
    "        csv_dir = os.path.dirname(output_csv)\n",
    "        csv_basename = os.path.splitext(os.path.basename(output_csv))[0]\n",
    "        excel_dir = os.path.join(csv_dir, 'excel_ver')\n",
    "        output_excel = os.path.join(excel_dir, csv_basename + '.xlsx') #one folder down from the csv\n",
    "        #output_excel = os.path.join(csv_basename + '.xlsx') #if in same folder\n",
    "        return output_excel\n",
    "\n",
    "    def process_texts(self, folder_path, output_csv, metadata_csv):\n",
    "        \"\"\"\n",
    "        Extract keyword contexts from all text files in a folder, enrich them with \n",
    "        metadata (extracted from data before in R), and save to a CSV. \n",
    "        Optionally converts the CSV to Excel.\n",
    "\n",
    "        Steps:\n",
    "        1. Loads metadata from a CSV file into a dictionary.\n",
    "        2. Iterates through each TXT file in `folder_path`.\n",
    "        3. Extracts text, finds contexts around keywords, and combines with metadata \n",
    "        (author, title, date).\n",
    "        4. Saves all contexts to `output_csv`.\n",
    "        5. Optionally creates an Excel version in a subfolder 'excel_ver'.\n",
    "\n",
    "        Args:\n",
    "            folder_path (str): Folder containing text files to process.\n",
    "            output_csv (str): Path to save the combined contexts CSV.\n",
    "            metadata_csv (str): Path to CSV containing metadata for the files.\n",
    "        \"\"\"\n",
    "        metadata = self.load_metadata_csv(metadata_csv)\n",
    "        all_contexts = []\n",
    "\n",
    "        txt_files = [f for f in os.listdir(folder_path) if f.endswith(\".txt\")]\n",
    "        print(f\"Beginning processing {len(txt_files)} text files in folder: {folder_path}\")\n",
    "\n",
    "        for filename in tqdm(txt_files, desc=\"Processing files\", unit=\"file\"):\n",
    "            txt_path = os.path.join(folder_path, filename)\n",
    "            text = self.extract_text_from_txt(txt_path)\n",
    "            \n",
    "            file_metadata = self._get_file_metadata(metadata, filename)\n",
    "            \n",
    "            if not file_metadata:\n",
    "                print(f\"No metadata found for {filename}\")\n",
    "                continue\n",
    "\n",
    "            author = file_metadata.get('author', '')\n",
    "            title = file_metadata.get('title', '')\n",
    "            date = file_metadata.get('date', '')\n",
    "\n",
    "            #skip after specific year (too new stuff shouldn't be included); the filename and year are actually somewhat different, might have been scraped metadata Date\n",
    "            if self.skip_after_specific_year:\n",
    "                if self._should_skip_by_year(date):\n",
    "                    continue\n",
    "            \n",
    "            contexts = self.find_contexts(text)\n",
    "\n",
    "            for keyword, context in contexts:\n",
    "                all_contexts.append((filename, keyword, context, author, title, date))\n",
    "\n",
    "        self.save_contexts_to_csv(all_contexts, output_csv) #might not need both csv and excel\n",
    "        \n",
    "        # Optionally create Excel file in excel_ver subfolder (easier to work with/possibly read)\n",
    "        # should be a separate function\n",
    "        if self.create_excel:\n",
    "            output_excel = self._create_excel_path(output_csv)\n",
    "            self.convert_csv_to_excel(output_csv, output_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"fact\", \"fiction\", \"facts\", \"facſ\", \"fictions\", \"ficſions\", \"factual\", \"fictional\", \"fictionally\", \"factually\", \"fictionality\", \"factuality\", \"fictionalized\", \"factualized\", \"fictive\", \"factive\", \"fictitious\", \"factious\"]\n",
    "#could add stemming instead of hardcoding them (so fact/facts automatically)\n",
    "\n",
    "extractor = TextContextExtractor(\n",
    "    keywords=keywords,\n",
    "    sentences_before=2,\n",
    "    sentences_after=2,\n",
    "    newest_year_included=1950,\n",
    "    skip_after_specific_year=True,\n",
    "    use_spacy=True, #nltk if False\n",
    "    create_excel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning processing 4390 text files in folder: D:/Fact_fiction_corpus/texts/royal society/txt_rsta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  69%|██████▉   | 3049/4390 [00:00<00:00, 6051.38file/s]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x0000025399AD8F10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Igiba\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 788, in _clean_thread_parent_frames\n",
      "    if phase != \"start\":\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "#RSTA (#royal society)\n",
    "extractor.process_texts(\n",
    "    folder_path=\"D:/Fact_fiction_corpus/texts/royal society/txt_rsta\",\n",
    "    output_csv=\"../data_to_view/contexts_all_together/contexts_RSTA.csv\",\n",
    "    metadata_csv=\"D:/Fact_fiction_corpus/texts/royal society/royalsociety_metadata_rsta.csv\"\n",
    ")\n",
    "\n",
    "#RSTB (#royal society)\n",
    "extractor.process_texts(\n",
    "    folder_path=\"D:/Fact_fiction_corpus/texts/royal society/txt_rstb\",\n",
    "    output_csv=\"../data_to_view/contexts_all_together/contexts_RSTB.csv\",\n",
    "    metadata_csv=\"D:/Fact_fiction_corpus/texts/royal society/royalsociety_metadata_rstb.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning processing 8520 text files in folder: D:/Fact_fiction_corpus/texts/royal society/txt_rstl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 8520/8520 [1:45:38<00:00,  1.34file/s]  \n"
     ]
    }
   ],
   "source": [
    "#RSTL (#royal society)\n",
    "extractor.process_texts(\n",
    "    folder_path=\"D:/Fact_fiction_corpus/texts/royal society/txt_rstl\",\n",
    "    output_csv=\"../data_to_view/contexts_all_together/contexts_RSTL.csv\",\n",
    "    metadata_csv=\"D:/Fact_fiction_corpus/texts/royal society/royalsociety_metadata_rstl.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning processing 1 text files in folder: D:/Fact_fiction_corpus/texts/General Magazine of Arts and Sciences/txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1/1 [00:36<00:00, 36.19s/file]\n"
     ]
    }
   ],
   "source": [
    "#General Magazine of Arts and Sciences (albeit empty)\n",
    "extractor.process_texts(\n",
    "    folder_path=\"D:/Fact_fiction_corpus/texts/General Magazine of Arts and Sciences/txt\",\n",
    "    output_csv=\"../data_to_view/contexts_all_together/contexts_general_magazine.csv\",\n",
    "    metadata_csv=\"D:/Fact_fiction_corpus/texts/General Magazine of Arts and Sciences/general_magazine_metadata.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning processing 632 text files in folder: D:/Fact_fiction_corpus/texts/spectator/txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 632/632 [02:19<00:00,  4.53file/s]\n"
     ]
    }
   ],
   "source": [
    "#The Spectator\n",
    "extractor.process_texts(\n",
    "    folder_path=\"D:/Fact_fiction_corpus/texts/spectator/txt\",\n",
    "    output_csv=\"../data_to_view/contexts_all_together/contexts_spectator.csv\",\n",
    "    metadata_csv=\"D:/Fact_fiction_corpus/texts/spectator/spectator_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: rsta_1887_0008.txt\n",
      "Keyword: fact\n",
      "Author: George Howard Darwin\n",
      "Title: VIII. Note on Mr. Davison’s paper on the straining of the Earth's crust in cooling\n",
      "Context: In that letter it is pointed out that the stratum of\n",
      "the Earth where the.rate of cooling is most rapid lies some miles below the Earth's\n",
      "surface. Commenting on this, I wrote :— ;\n",
      "\n",
      "“The Rev. O. FisHer very justly remarks that the more rapid contraction of the\n",
      "internal than the external strata would cause a wrinkling of the surface, although he\n",
      "does not admit that this can be the sole cause of geological distortion. The fact that\n",
      "the region of maximum rate of cooling is so near to the surface recalls the interesting\n",
      "series of experiments recently made by M. Favre (‘ Nature,’ vol. 19, p. 108), where\n",
      "all the phenomena of geological contortion were reproduced in a layer of clay placed\n",
      "on a stretched india-rubber membrane, which was afterwards allowed to contract. Does it not seem possible that Mr. Fister may have under-estimated the contractibility\n",
      "of rock in cooling, and that this is the sole cause of geological contortion ?”\n",
      "\n",
      "Mr. Davison works out the suggestion, and gives precision to the general idea con-\n",
      "tained in the letter. He shows, however, that there is a layer of zero strain in the ~\n",
      "\n",
      "\n",
      "\n",
      "IN THE EARTH’S CRUST RESULTING FROM SECULAR COOLING.\n",
      "\n",
      "Filename: rsta_1887_0008.txt\n",
      "Keyword: fact\n",
      "Author: George Howard Darwin\n",
      "Title: VIII. Note on Mr. Davison’s paper on the straining of the Earth's crust in cooling\n",
      "Context: The term “stretching” then requires an explanation in connection with. .Davison’s paper. The stretching which we have to consider is, in fact, simply the\n",
      "\n",
      "@xcess of the actual stretching above that due to rise of temperature. The negative\n",
      "@f such stretching is a contraction, and it would actually be shown by a crumpling\n",
      "Sof strata.\n",
      "6 if p be the density of a body, and ¢ its modulus of linear expansion for temperature,\n",
      "®khen it is obvious that when the temperature is raised 0 degrees the density becomes\n",
      "op (1 — 34). Now suppose that a spherical shell of radius 7 expands so that its\n",
      "‘radius becomes 7(1-+ «), and suppose that at the same time its temperature is raised\n",
      "0 degrees.\n",
      "\n",
      "Filename: rsta_1887_0008.txt\n",
      "Keyword: fact\n",
      "Author: George Howard Darwin\n",
      "Title: VIII. Note on Mr. Davison’s paper on the straining of the Earth's crust in cooling\n",
      "Context: erties Lagos (11) Thus it appears that the integral effect is always a stretching, and that it is the\n",
      "\n",
      "same in amount at whatever speed the globe cools. The fact that, if the globe cools\n",
      "\n",
      "suddenly, the integral effect must be stretching has been pointed out by Mr. Davison. If we differentiate (10), we have\n",
      "\n",
      "dK _ [ dv 3« V |\n",
      "\n",
      "x dt ~ dt (wet)\n",
      "But\n",
      "\n",
      "e oN. PE\n",
      "\n",
      "& dt” 2t dx\n",
      "‘gund, near the surface,\n",
      "\n",
      "2 dv ety!\n",
      "\n",
      "Filename: rsta_1887_0007.txt\n",
      "Keyword: fact\n",
      "Author: Charles Davison\n",
      "Title: VII. On the distribution of strain in the Earth's crust resulting from secular cooling; with special reference to the growth of continents and the formation of mountain chains\n",
      "Context: If the globe were absent, the radius of its inner\n",
      "Surface would become 7(1 —et,). It is, however, obliged to remain of radius 7, and\n",
      "& must, therefore, be stretched. Assuming the stretching to be uniform throughout\n",
      "fhe shell, and expressing the fact that the volume of the shell after cooling ¢,° is\n",
      "Equal to its original volume multiplied by 1 — 3et,, it will be found that the radius of\n",
      "Bhe outer surface of the shell is\n",
      "\n",
      "A 3 3\n",
      "\n",
      "ob 6 ican\n",
      "\n",
      "¢ i — a hs\n",
      "Be \"\n",
      "4vhere 5\n",
      "3 7 r=rt+ a.\n",
      "\n",
      "2 Proceeding in a similar manner with the other shells, and remembering that the\n",
      "Zadius of the inner surface of any shell after cooling must be the same as the radius\n",
      "af the outer surface of the shell below after its cooling, then the radius of the inner\n",
      "Gurfce of the shell A,,,, becomes\n",
      "\n",
      "= (7,3 - 1) etn + Ga-i5 = =5°) y_ + ... + (r8— 1°) ef\n",
      "&\n",
      "ENow, lot ¢p—d,—=., «=a; also let t= 0%, ty —t = Oh, ..« -» beg, — be = Ole\n",
      "\n",
      "‘gt the shell A,,, had been allowed to contract, as if the globe and interior shells\n",
      "‘Bvere absent, the radius of its inner surface would have been (1 + na) (1 — et, 41). Allence the amount by which a great circle of the inner surface of this shell is\n",
      "stretched is proportional to\n",
      "\n",
      "Ga nail (7 + na)? Btu + (r+ —1.a)).\n",
      "\n",
      "Filename: rsta_1887_0007.txt\n",
      "Keyword: fact\n",
      "Author: Charles Davison\n",
      "Title: VII. On the distribution of strain in the Earth's crust resulting from secular cooling; with special reference to the growth of continents and the formation of mountain chains\n",
      "Context: Commenting on this, I wrote :— ;\n",
      "\n",
      "“The Rey. O. FisHER very justly remarks that the more rapid contraction of the |\n",
      "internal than the external strata would cause a wrinkling of the surface, although he\n",
      "does not admit that this can be the sole cause of geological distortion. The fact that\n",
      "the region of maximum rate of cooling is so near to the surface recalls the interesting\n",
      "series of experiments recently made by M. Favre (‘ Nature,’ vol. 19, p. 108), where\n",
      "all the phenomena of geological contortion were reproduced in a layer of clay placed\n",
      "on a stretched india-rubber membrane, which was afterwards allowed to contract. Does it not seem possible that Mr. Fisser may have under-estimated the contractibility\n",
      "of rock in cooling, and that this is the sole cause of geological contortion ?”\n",
      "\n",
      "Mr. Davison works out the suggestion, and gives precision to the general idea con- —\n",
      "tained in the letter. He shows, however, that there is a layer of zero strain in the\n",
      "\n",
      "Filename: rsta_1887_0005.txt\n",
      "Keyword: fictitious\n",
      "Author: Horace Lamb\n",
      "Title: V. On ellipsoidal current-sheets\n",
      "Context: The current lines are the orthogonal projections on the plane ay of the contour lines of spherical\n",
      "harmonics drawn on a sphere of radius a.\n",
      "+ F. E. Neumann has shown (‘ Crelle,’ vol. 37) how to expand the potential of a single magnetic pole\n",
      "in this way. x2\n",
      "\n",
      "\n",
      "156 PROFESSOR H. LAMB ON ELLIPSOIDAL CURRENT-SHEETS,\n",
      "\n",
      "the left-hand side being obtained as the electromotive force necessary to balance t\n",
      "resistance, and the right-hand side as the electromotive force of induction due to\n",
      "decay of the currents. Ifz be the modulus of decay of the type in question,\n",
      "\n",
      "Now let ¢ represent a fictitious distribution of current over the ellipsoid, which shall\n",
      "have the same magnetic effect in the interior as the actual inducing field. This\n",
      "distribution is found at once from (69). The equation of induced currents will then be\n",
      "\n",
      "or\n",
      "\n",
      "When the free currents have died away all our functions will vary as e”, where p\n",
      "measures the rapidity of the changes in the field.\n",
      "\n",
      "Filename: rsta_1887_0005.txt\n",
      "Keyword: fictitious\n",
      "Author: Horace Lamb\n",
      "Title: V. On ellipsoidal current-sheets\n",
      "Context: ee\n",
      "\n",
      "The system of currents is stationary in space, but is displaced relatively to the Sell\n",
      "by a greater or less angle\n",
      "\n",
      "1\n",
      "3 are tan spr,\n",
      "\n",
      "according to the speed of rotation. The maximum value of this is 7/2s for a suffi- |\n",
      "ciently rapid rotation, ‘\n",
      "\n",
      "* This represents a fictitious distribution of currents\n",
      "\n",
      "which would give at all points of the disk the\n",
      "same normal force as the actual field. PROFESSOR H. LAMB ON ELLIPSOIDAL CURRENT-SHEETS, 159\n",
      "\n",
      "The most important type of induced currents is got by putting n = 2, s = 1, in (95). In this case\n",
      "Dc a,\n",
      "so that the lines of force at the disk are normal to it, but the direction of the force is\n",
      "reversed as we cross the axis of y.\n",
      "\n",
      "Filename: rsta_1887_0010.txt\n",
      "Keyword: fact\n",
      "Author: James Joseph Sylvester\n",
      "Title: X. On Hamilton's numbers\n",
      "Context: E%; = :\n",
      "4 — Bas =) = — ./8 wheni =o.\n",
      "\n",
      "3 Let A, p, v,... represent the halves of the Hypothenusal Numbers in the triangle\n",
      "Ziven at the commencement of the paper, i.c., the differences of the numbers which\n",
      "Sve have called p, g,7,..-\n",
      "\n",
      "Since\n",
      "\n",
      "x p=PF-3¢e and g= rt — Fr\",\n",
      "\n",
      ": p—q=P—-te—-g ond gor=r—gr—r.\n",
      "\n",
      "Z Obviously, therefore, as a first approximation when }, p, are very advanced terms\n",
      "in the hypothenuse,\n",
      "\n",
      "Let us write\n",
      "\n",
      "for a second approximation. * Asa matter of fact, it will be found that, as soon as g and p attain the values 6, 24, g? — $ q' may\n",
      "be taken as a superior limit. It may be noticed also, to prevent a wrong inference being drawn from the\n",
      "above expressions, that, as will hereafter appear, 7 is an infinitesimal of the order 1/q*, when q is\n",
      "infinite. 296 PROFESSOR SYLVESTER AND MR. J. HAMMOND\n",
      "\n",
      "Th\n",
      "an @—t? —g=(*®—te 1h +k —F e\n",
      "\n",
      "or, neglecting terms of lower dimensions than ae;\n",
      "P 9 1 1 ee ¢\n",
      "(2 — BrP — gr Lis ach reams)\n",
      "\n",
      "Filename: rsta_1887_0010.txt\n",
      "Keyword: fact\n",
      "Author: James Joseph Sylvester\n",
      "Title: X. On Hamilton's numbers\n",
      "Context: *\n",
      "\n",
      "on\n",
      "\n",
      "5 As a verification, since 2° = 8, (1°46544)* should lie between 18 and 24; and, as a\n",
      "on . . Batter of fact, a rough calculation gives\n",
      "\n",
      "n\n",
      "\n",
      "S (1°46544)? = 2°1478...,\n",
      "3 (2047ey = 4608). 3,\n",
      "3 (4°608)® = 21234 ...,\n",
      "\n",
      "lo}\n",
      "Shich is about midway between the two limits.- J. J. 8.\n",
      "\n",
      "Filename: rsta_1887_0010.txt\n",
      "Keyword: fact\n",
      "Author: James Joseph Sylvester\n",
      "Title: X. On Hamilton's numbers\n",
      "Context: — 2. Tn this equation we may write\n",
      "\n",
      "Vr=g+h,\n",
      "Js= gt + hg 3\n",
      "\n",
      "2 — 3 equations),\n",
      "JVt= qitt ky - ence\n",
      "\n",
      "Yt\n",
      "Shere I, key, ks, ... are all of them finite (and, as a matter of fact, of no consequence for our immediate\n",
      "Biect, positive proper fractions). For, ultimately,\n",
      "\n",
      "Wari | eye in\n",
      "2 k= Vr— g= n+ gt o. Te aa $0, = 3 (see p. 307),\n",
      "\n",
      "wad consequently the finiteness of each & is a direct inference from the general principle previously\n",
      "plied in the case of the «’s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing the output txt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data_to_view/contexts_all_together/contexts_RSTA.csv\")\n",
    "\n",
    "for index, row in df.head(10).iterrows():\n",
    "    print(f\"Filename: {row['Filename']}\")\n",
    "    print(f\"Keyword: {row['Keyword']}\")\n",
    "    print(f\"Author: {row['Author']}\")\n",
    "    print(f\"Title: {row['Title']}\")\n",
    "    print(f\"Context: {row['Context']}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system(f\"shutdown /s /t 60\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
