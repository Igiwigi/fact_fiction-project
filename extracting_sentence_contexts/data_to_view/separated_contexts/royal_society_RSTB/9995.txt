Because they are translated and


Figure 1. Computer vision approaches. (a) Early photogrammetry methods tracked features across a sequence of frames and calculated a set of three-dimensional
points and a camera path that would best explain the tracks (Image courtesy of Oxford Metrics (OMG plc), [10]). (b) ‘Dense SLAM’ now achieves the same result but
for a very dense reconstruction of surfaces and is done in real time (© Reprinted from Newcombe et al. [11] with permission from IEEE). (c) Sometimes it is very
difficult to calculate the three-dimensional structure of a scene, as here, and for many purposes solutions that avoid three-dimensional reconstruction are optimal (in
this case, synthesising a novel view given several input views; © Reprinted from Fitzgibbon ef al. [12] with permission from IEEE). (d) Recent approaches to SLAM
incorporate views at certain locations (5, and 5, here, called ‘keyframes’) and store these, along with the rotation and translation required to move between them, as
a graph (Reprinted from Twinanda et a/. [13] with permission from the authors). (Online version in colour.)

rotated as they move through the wormhole, no coherent (c) Cortical representations
(wormhole-free) two-dimensional map of the environment is It is often said that posterior parietal cortex represents the
possible. The fact that participants do not notice and can per- scene in a variety of coordinate frames [34,35], as shown in
form navigation tasks well suggests that they are not using figure 3a. The clearest case for something akin to a three-
a cognitive map but their behaviour is consistent with a dimensional coordinate frame is in V1. Here, receptive
topological representation formed of a graph of views. fields are organized retinotopically and neurons are sensitive
Some behaviours are more difficult to explain within a to a range of disparities at each retinal location (e.g. [37]).
view-based or sensory-based framework.