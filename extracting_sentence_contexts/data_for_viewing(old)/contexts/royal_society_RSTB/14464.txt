According to the counterfactual simulation model, the 1 preferred not to say) were recruited via Amazon Mechan-
probability that x caused y is given by ical Turk using psiTurk [62]. Only participants based in the

USA with an approval rating of 95% or higher were able to

participate [63].
P(X > ¥) = PY b& ¥)- (2.2)

(ii) Design and procedure

The experiment had two conditions that differed in whether
The more likely ball B would have missed the gate if ball A participants were asked to answer a hypothetical question
had not been there (yx), when it fact ball A was present (x) about what would happen if ball A was removed, or a coun-
and ball B went into the gate (y), the more likely ball A terfactual question about what would have happened if ball
caused ball B to go into the gate.* A had been removed.

Experiment 1 tests whether the simulation model accu- The instructions in both conditions were largely identical.
rately captures participants’ hypothetical and counterfactual Participants were told that their task would be to make judge-
judgements. Experiment 2 then tests whether participants’ ments about video clips, and they viewed two diagrams
causal judgements are better explained by hypothetical simu- similar to those in figure 6 illustrating what the clips will look
lations (equation (2.1)), or by counterfactual simulations like. Participants learned that in each clip, two balls, ball A

(equation (2.2)). and ball B, enter the scene from the right and collide with one

