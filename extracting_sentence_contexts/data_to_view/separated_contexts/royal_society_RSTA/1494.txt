Exploiting data sparsity

In this section, we address the problem of dealing with large volumes of data by exploiting ‘data
sparsity’. This problem arises in many applications, ranging from scientific computing where
complex phenomena are simulated over large domains and long periods of time, to machine
learning where large volumes of data are processed. Data sparsity refers to the fact that, due to
redundancy, the data can be efficiently compressed while controlling the loss of information. A classic example in this context is the n-body problem in physics for which some forces
between all pairs of n particles are computed with O(n) flops by using the fast multipole method
(FMM) [69], while a direct evaluation of these forces requires O(n?) flops. This method relies
on treating separately the contributions from near particles, which are computed directly, from
contributions from distant particles, which are evaluated by using multipole expansions.