According to this narrative, if AI robots were ‘electronic persons responsible for making good any
damage they may cause’, in the phrasing of the EU Parliament's resolution from 2017, we should
be ready to tackle ‘two kinds of abuse that might arise at the expense of human legal rights—
humans using robots to insulate themselves from liability and robots themselves unaccountably
violating human legal rights’ [3, p. 285]. In the first case, the agenthood of artificial agents could
be a means to shield humans from the consequences of their conduct. Damages provoked by the
behaviour and decisions of AI systems would not be upon the fat cats of Silicon Valley, because
only an AI system would in fact be liable. In the second case, we should expect cases of robot
insolvency: ‘money can flow out of accounts just as easily as it can flow in; once the account is
depleted, the robot would effectively be unanswerable for violating human legal rights’ [3, p.
288]. Traditional punitive sanctions of the law, such as jail time for criminal insolvency, would be
unavailable, unsatisfying or ineffective.