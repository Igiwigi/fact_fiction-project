version in colour.)

the column basis tree U of the third step. While FMM computations are only possible when there : =
is an analytical kernel that can be evaluated, hierarchical matrices, by explicitly storing matrix D8
blocks algebraically, can naturally handle general dense problems and not restricted to matrices are
with an underlying analytical kernel. 1
When performing matrix-vector multiplication with multiple vectors rather than a single one, 1
the increased arithmetic intensity produces substantial performance benefits over single vector 4
operations both on CPUs and GPUs as shown in figure 9. By replacing the batched dense DA
matrix-vector routines by corresponding batched dense matrix matrix (GEMM) routines, the
hierarchical matrix multiplication operation inherits all the performance benefits of the latter.
This effect is more pronounced on GPUs because of their deeper memory hierarchies, and the
high parallelism and coalesced memory accesses of the compute-bound GEMMs. In fact, the
multiple vector operation can achieve a substantial portion (greater than 90%) of the batched
GEMM performance, which on the P100 is about 1.6 TFLOP/s in double and 2.8 TFLOP/s in
single precision.
Next, we consider a low-rank update operation, since a number of algorithms in the library
use an operation of the form A= A+ XY as a building block. The low-rank update could be
a global update where X and Y are dense matrices of size n x r, or could be a set of local
low-rank updates affecting only a portion of the matrix A, where rows of X and Y represent
a subset of the n matrix rows. The first step in the low-rank update operations is to add the
appropriate contributions of XY7 to the various matrix blocks at all levels. This of course increases
the apparent rank of the blocks by r. The key task in executing the update efficiently is then to
recompress the resulting matrix to the desired accuracy of the target approximation. This involves
the generation of a new nested basis and compressing all blocks using it [25]. The key kernels