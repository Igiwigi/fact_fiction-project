In fact, there is evidence pointing in this direc-
have such conversational functionality. Thirdly, there is a tion from one study [10], showing that participants actually
further reason why people may incorrectly perceive robots favoured robots who made mistakes, as this made them
to be underperformingâ€”i.e. people are typically unfamiliar more human-like. However, the point stands that many cus-
with the workings of robots and may sometimes misjudge tomers in a retail scenario may be more impatient and more
that a robot has broken down when, in fact, it is taking demanding when they are shopping for something than
longer to perform an action than expected simply because when they are interacting with a robot in an experimental
it is recalibrating or exploring the learning space [31]. scenario. Fourth, there may be important negative consequences Consider a different type of case: human disengagement
of human disengagement in response to (perceived) robot in response to robot overperformance. While we are not
underperformance. aware of any research directly investigating this possibility

The negative consequences of human disengagement in the context of human-robot interaction, there has been rel-
may range from opportunity costs (e.g. the human decides evant research in the context of human reliance on automated
to go to a different shop or service provider where she/he systems [36].