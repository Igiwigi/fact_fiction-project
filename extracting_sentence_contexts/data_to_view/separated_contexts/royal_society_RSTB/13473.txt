In the case of previously
untrustworthy Agents (who were generally disadvantageous
to interact with), participants who acted on positive lies had
significantly lower payoffs than those acting on the truth
(b = -0.80, r (1) = 17.44, p < 0.001), while those who acted on
negative lies were not significantly disadvantaged (b = —0.32,
C (1) = 0.90, p = 0.344). In the case of previously trustworthy
Agents (who were generally advantageous to interact with),
participants who acted on positive lies had significantly
lower payoffs than those acting on truth (b =—0.90, C (=
9.12, p= 0.003), while those who acted on negative lies were
again not significantly disadvantaged (b = —0.28, C (1) =2.51,
p=0.113). This pattern for previously trustworthy Agents dif-
fers somewhat from study 1 and is due to the fact that the
populations of Agents underlying each type of message were
not identical (see tables 2.4 and 2.5 in the electronic supplemen-
tary material). We have no good reason for why this occurred,
apart from random chance.

(iii) Detecting dishonest gossip

Our findings are again consistent with the possibility that dis-
honest gossip may erode the ability for gossip to bolster
cooperation. We now test H2 and the claim that people will
evaluate dishonest gossip as less accurate than honest gossip.