Section 4c sheds light on a variant of the previous arguments, so that, if AI robots are grasped 1a

as agents in contracts and business law, then some form of corporation follows as a result. While
the aforementioned 2018 letter of AI experts to the EU Commission recalls ‘the Anglo-Saxon Trust
Model’, attention should be drawn in this context to another model, that is the Ancient Roman
law idea of ‘peculium’.

Section 4d dwells on the narrative of AI robots as ‘unaccountable right violators’, or mere
liability shields for humans. According to this stance, i.e. the ‘two abuses’ doctrine, granting AI
robots legal personhood would be morally unnecessary and legally troublesome, for holding AI
robots accountable outweighs the highly precarious moral interests that AI legal personhood
might protect [3]. Although this argument has its strengths, it still confuses the apples of legal
accountability with the oranges of legal personhood. As a matter of fact, in the legal domain, it is
not true that, if we do not have apples, neither oranges as a result.

The final part of the paper offers a map on how we may tackle the normative impact of AI
robots on the civil (as opposed to the criminal) law field. Contrary to current trends of the debate
on the legal status(es) of Al robots, §5 advocates a pragmatic approach. By distinguishing between
the primary rules and the secondary rules of the law, §6 illustrates some implementations of this
approach to the ethical and legal challenges of AI robots. Methods of legal flexibility regard the
special zones, or Tokku, set up by the Japanese government over the past 15 years, as well as
cases of legal experimentation in the field of autonomous vehicles, up to the EU regulation on
data protection (GDPR). By taking into account the normative challenges of AI robots, their legal
status reminds us of the problem Romans used to have two millennia ago: in their view, slaves
were things that nonetheless played a crucial role in trade and commerce. AI robots and enslaved