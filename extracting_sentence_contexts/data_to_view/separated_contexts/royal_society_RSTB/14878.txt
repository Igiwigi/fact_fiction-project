Beyond the practical problem of needing to marginalize
over all the senses and states, there is also a conceptual
problem in that Bayesian multisensory models purport that multisensory processing a host of brain functions that deal
some brain circuit receives ‘unisensory’ observations as
input. For example, the well-known ‘causal inference’ model
[2] (figure 1b) describes how best to decide whether two
unisensory observations (e.g. audio, xq and visual, xy) were different purposes, including
caused by one source (C = 1, bottom left panel), in which case integration, suppression, etc.
they should be integrated, or two separate sources (C =2,
bottom right panel), in which case they should not be inte-
grated. But these ‘unisensory’ observations are in fact each a
result of multisensory processing. They depend on the states modalities into a unified estimate
and input from other senses (grey circles and arrows in of the stimulus
figure 1b), e.g. proprioceptive signals from the eyes and neck,
vestibular signals from the head, and corollary discharge
from intended movements, all strongly influence visual and
auditory observations [5,6,37-41]. presence of another stimulus from

a different modality

with multiple sensory modalities’
inputs and states—for a variety of

multisensory integration combining multiple sensory
measurements from different

multisensory suppression the neuronal or behavioural responses
to a stimulus are reduced by the

Moreover, sensory systems are not passive receivers.

; multisensory interactions when the response or measurement

Rather, they are part of sensorimotor loops. Not only do . .

. . (or dependencies) from one modality depends on the
the movements we make influence sensations, humans and
animals actively move to sense the environment (active sen- state (or input) of another
sing) [42,43].