[65]. While Twitter’s Privacy Policy states that its services are public and that private accounts
are removed from data streamed through Twitter’s Streaming API [66], critical data studies have
highlighted the risks that public trace data pose to the subjectivity of individual users. Although
public, users might hold a reasonable expectation that the publicness of their activities will not
infringe on their privacy or make them vulnerable to unintended scrutiny and even abuse [67],
an expectation only likely to grow in the aftermath of the Cambridge Analytica data scandal [50].

The potential vulnerability of users engaging in politically charged debates poses important : =
ethical challenges. Many of the Twitter handles flagged as Brexit bots included important : =
information to the story we sought to tell, including political slogans, party or campaign 1B
affiliation, and ideological leanings. The semantics of usernames was thus an important part of : =
the story, leading us to identify 11 handles of suspected bots (e.g. EuFear and @no_eusssr_thx). DR
After putting in balance the risks of false positives and the fact that the accounts had disappeared : o
from the platform shortly after the vote, we decided to disclose the Twitter handles in the interest :m
of accountability. We did so whenever there was a reasonable level of confidence that we were :2
dealing with Twitterbots, to which ethical considerations of privacy are immaterial. Yet, we are : S

BS

cognizant of at least two false positives in our study. These accounts were nonetheless important
to the story due to their central position in the bot network and their role in sourcing content to
bots. We also recognize that the claim of account automation was not intrinsically harmful as it is
not in breach of Twitter’s Terms of Service.

These considerations can only be properly managed within the context of the research, namely