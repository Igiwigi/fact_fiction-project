
where ft is the current timestep, x,,, is the point that is map- icies for which competence is still low (see also §3d; see [67]
ping the sensory state s for the sensory modality i¢€{1, for a similar use of local modulation in SOMs). This two-
2,..., Nst, ¥q is the point that is mapping the policy initially folded mechanism for setting the learning rate allows us to
selected for the current episode and x,, is the point that is avoid catastrophic forgetting when using algorithms such
mapping the policy with added random noise, which is the as SOMs or STMs with an online stream of data (lifelong
one actually used in the episode. learning, [68]). Finally, the local statistic about competence
Once & is computed, we can transform it into a radial given by the predictor component is also used to arbitrate

function to obtain a measure €; whose maximum is 1 when between exploration and exploitation in choosing the current


policy. In particular, when the local competence for the cur- sensorimotor representations: visual features are in fact | 8 |

rent policy is close to 0 (low competence) a higher amount used to select the relevant policy in each episode.
of noise is added to the policy so that new policies can be 3
tried out. Instead, a high value (close to 1) in the local com- (a) The simulated environment z
petence indicates that a given policy can be ‘exploited’ so . : : : 4 . S
. . _ The simulation setting consists of a two-dimensional <=
that there is no further need of exploring and no additional . as . . . Ss
environment with interactions defined by force dynamics. 5

noise is added. . . . . =
The environment contains the agent, a two-dimensional = =
