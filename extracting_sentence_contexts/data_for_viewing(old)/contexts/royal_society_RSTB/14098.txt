Cross-validation methods divide the original dataset into axis, positive-predictive-value on the y-axis) curves (figure 1).
two—one which is used to fit the model (called the training These curves are generated by considering a continuum of
set) and one used to validate its predictive accuracy on the thresholds of classifier acceptance, and computing the values
data that it hasn’t ‘seen’ yet (called the test set) [106]. This pro- of ROC/PR metrics for each value of the threshold. The area-
cedure is often repeated across different test and training under-the-curve (AUC) is then used as a validation metric and
subdivisions of the dataset (either picked randomly or strati- are typically called area-under-the-curve receiver-operator-
fied by some criteria, like balance between positive and curve (AUC-ROC) and area-under-the-curve precision-recall
negative interactions in the case study) to determine the (AUC-PR) (e.g. ROC-AUC in table 1). These measures have
uncertainty associated with our measurement owing to our the unstated assumption that the training and testing set are
choice of test and training sets [107], in the same conceptual ‘correct,’ or at least correct enough that the number of true/
vein as data bootstrapping: the mean value of the validation false positive/negatives are meaningful; although should this
metric gives an overall estimate of its performance, and the assumption be true, there would be no need for any predictive
variance around this mean represents the effect of using approach—but it is a well established fact that ML systems are
different data for training and testing. In a robust model/ resilient to even relatively high uncertainties in the data [45].

dataset combination, we expect this variance to be low,
although there are no prescriptive guidelines as to how

little variance is acceptable; the choice of whether to use a (b) Networks and interactions as predictable objects
model is often left to the best judgement of the modeller. (i) Why predict networks and interactions at the same time?
We still have to define what predictive accuracy means Ecological networks are quite sparse, and larger networks
in the context of interaction network prediction. In the tend to get sparser [111]; in other words, although networks
proof-of-concept, we used a neural-network to perform are composed of a set of interactions between species pairs,
binary classification by predicting the presence/absence of they also form a much larger set of species pairs that do
