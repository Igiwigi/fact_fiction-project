www.theguardian.com/technology/2017 /may /07/the-great-british-brexit-robbery-hijacked-democracy. But the broader
social media and fake news discussions similarly highlight the manipulative powers of the opaque selections algorithms
provide. See also [23,5758].


of algorithms and the socio-technical systems they are part of (in short: algorithms) (e.g. [59]). As a 4 |
result, efforts to mitigate the problems associated with ANR therefore focus on more transparency

about the precise workings of algorithms (e.g. [60,61]). But algorithms are notoriously difficult 2
to grasp and understand, even for trained people like computer scientists (cf. [62,63]). This is :
partly because of proprietary reasons, most operators keeping their algorithms secret to maintain
competitive advantage, to prevent adversarial learning and gaming (cf. [64,65]). But making the
workings of algorithms transparent or explainable is further complicated by the fact that they
are often complex entities with a difficult genealogy: they are the product of many interventions,
by many different people, with different interests, values and goals (cf. [66-68]). Algorithms are
always in flux, because they continuously interact with many different actors (other algorithms,

users, developers, aggregate data, etc.) and in various different settings (cf. [69-71]). This makes it : &
hard to pinpoint what exactly can be made transparent. Especially as algorithms are increasingly
programmed to improve autonomously, they may become even more elusive, moving beyond :=
the human capacity to grasp and understand.Â® Recent calls and efforts for more transparency as gs
an ethical principle and a practical means to understand and govern algorithms (cf. [64,72]) may : a
therefore be falling short [73]. : XS

Instead of trying to make ANR more transparent, we explore in this article ways to give people : _