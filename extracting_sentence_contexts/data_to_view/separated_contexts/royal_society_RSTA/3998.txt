Because the local plasma frequency is proportional to
the square root of the ion number density, transmitting radio pulses with a range of shortwave
frequencies revealed the height profile of free electrons, with the time of flight of the signal being
used to estimate the height of the ionospheric layers. During a solar eclipse, with ion production removed at totality, the loss rate, L, was estimated
from the time delay between totality and the subsequent minimum in atmospheric ionization. These experiments invariably underestimated the loss rate due to the fact that, while emissions
from the visible solar disc were obscured by the Moon at totality, emissions from the solar
corona were not. Using eclipse experiments to determine loss rates fell out of fashion after
sounding rockets were developed that could make direct measurements of upper atmospheric
composition. Now that these loss rates are well known, these early eclipse experiments have
been re-interpreted to estimate how the relative size of the solar corona has varied throughout
the twentieth century [116,117].