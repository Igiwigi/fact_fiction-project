The topological entropy is the least upper bound
over all parameters of the logarithm of the orbit number No. Although the topological entropy and the computing exponent are defined similarly, two
apparent differences exist: when counting functions and orbits, the function number depends
only on the final symbols while the orbit number depends also on the intermediate symbols;
furthermore, the function number depends only on groups of final symbols, not on the final
symbols individually. Because the set of functions is a fair sample of the set of orbits, we expect the
computing exponent to be similar to the topological entropy, and in fact numerically we observe
AL SAc © Ag and we conjecture that the final equality is true in general.

(c) Numerical examples

The approach we use in this paper to estimate the computing exponent is a kind of ‘analysis
by synthesis’ in the sense that we analyse and measure the computing power of the system by
actually trying different configurations and counting the number of different functions that the
system in these different configurations can implement. Of course, we cannot apply and try all
possible configurations in a system with continuous variables; however, we can use a subset of
these configurations to get a measure on the number of different observed functions, and estimate
the rate at which the number of these functions increases as evolution time increases. This rate,
which is an exponent, and we named it the computing exponent, is independent of the details
of the analysis by synthesis method for its estimation, such as the size of data input ng, or the
size of control inputs ¢ or the base of the computation (the number of levels for each symbol).