From the perspective : =
of the physician, the frameworks allow us to understand whether the decision taken relied on a 13
known domain knowledge by highlighting the corresponding ECG wave, thus the trust in the : =
deep learning model can be increased. :8

Under a supervised classification framework, an ML algorithm takes a decision that is : 4
represented by the classification output itself. As a consequence, ML decision-makers can be : e
trusted relying only on their predictive performance evaluated on the dataset available. Our effort aS]
in the direction of developing an interpretability methodology relies on the fact that we believe :s
it necessary that future advancement in automatic processing of ECG progresses together with 7B

our capability to understand the decisions taken by an ML model. In this way, the large accuracy
which ML algorithms might obtain in the future will also contribute to our understanding of the
underlying physiology. Similar considerations were already present in the thinking of the ancient Greeks to obtain
what Aristotle defined as téxvn [téchne]: a real productive science [34].