a random matrix, units tuned to number spontaneously pairs of vector states between 1 and 4, and then tested them
emerge: simulations show that, for every number i, including on the 72 number pairs between 1 and 9, thus evaluating
zero and up to 30, one can find units whose activity peaks at their capacity to generalize to numbers outside of the original
iteration i (see electronic supplementary material, Note S2). training range (see electronic supplementary material, Note
Furthermore, the average normalized activation of all model S5). Figure 3a shows simulated accuracies averaged over all clas-
units that prefer a given number i parallels the log-Gaussian sifiers, for each possible number pair. Matching the empirically
tuning curves reported in actual neuronal recordings [7]. On observed performance of monkeys (figure 3b), the classifiers’
a linear scale, tuning curves overlap and show increasing performance exhibits a distance effect and is above chance in
skews, as reflected by increased responses to the numerosities comparing pairs of numbers that both fall outside of the train-
immediately next to the peak of the curve, as numerosity ing range 1-4 (novel/novel pairs, property D4). It may seem
increases. Once plotted on a log scale, however, tuning counterintuitive that an arbitrary vector, iteratively updated
curves become symmetrical and of similar width (D2). These by a random matrix, produces a non-random sequence of
properties reflect the fact that under weak conditions on M states that contains generalizable information about numerical
and So, the von Mises iteration converges geometrically (see order. However, the presence of a spontaneous order in
electronic supplementary material, Note $9). Furthermore, vector space arises naturally from the slow convergence of the
if units are binned according to their preferred number ‘von Mises’ algorithm to the first eigenvector (i.e. with largest
(figure 2c), a U-shaped distribution emerges (D3), with more eigenvalue) of matrix M, and is attested by multi-dimensional
units selective to the lowest and highest tested numerosities, scaling (figure 2¢,h).
in agreement with the experimental data (figure 2d). Infant recovery-from-adaptation paradigms [5] can be
Next, we ask whether the model is capable of assigning dis- simulated by training a one-class support vector machine
tinct vector states to larger numbers. Without changing any on noisy vector states obtained from different runs of the
parameters, we produce 30 consecutive number states by suc- same model for the same numerosity (see electronic sup-
cessive application of matrix M to the initial vector Sp. We then plementary material, Note S6). When tested with a new
compare these theoretical vectors with the empirical vectors of vector state that either matches or differs from the familiar
firing rates of PFC number neurons recorded in monkeys pre- numerosity, emulating the procedure in [5], the classifier